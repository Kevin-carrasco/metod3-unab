[
  {
    "objectID": "practicos/practico-02.html",
    "href": "practicos/practico-02.html",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "En esta práctica nos enfocaremos en el significado de las parcializaciones en la regresión múltiple. Para ello utilizaremos el ejemplo 3.1 de Wooldrige (2010) cap. 3 (Análisis de regresion múltiple) (p.68-80) sobre las determinantes del promedio en la universidad.\n\n\n\npacman::p_load(ggpubr, #graficos\n               dplyr, #manipulacion de datos\n               sjPlot, #tablas\n               gridExtra, #unir graficos\n               texreg, #mostrar regresion multiple\n               summarytools, #estadisticos descriptivos\n               wooldridge) #paquete con los ejemplos del libro\nlibrary(wooldridge)\n\n\n\n\nLos datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene variables:\n\n\\(colGPA\\): promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\n\\(hsGPA\\) : promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\n\\(ACT\\) : puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\n\nPrimero, se cargará la base de datos que contiene la librería wooldrige y se seleccionarán las variables señaladas\n\ndata('gpa1') # Cargar base de datos\ngpa1 &lt;- dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables\n\n\n\n\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\n\nview(dfSummary(gpa1, headings = FALSE, method = \"render\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\ncolGPA [numeric]\n\n\n\nMean (sd) : 3.1 (0.4)\n\n\nmin ≤ med ≤ max:\n\n\n2.2 ≤ 3 ≤ 4\n\n\nIQR (CV) : 0.5 (0.1)\n\n\n\n19 distinct values\n\n141 (100.0%)\n0 (0.0%)\n\n\n2\nhsGPA [numeric]\n\n\n\nMean (sd) : 3.4 (0.3)\n\n\nmin ≤ med ≤ max:\n\n\n2.4 ≤ 3.4 ≤ 4\n\n\nIQR (CV) : 0.4 (0.1)\n\n\n\n16 distinct values\n\n141 (100.0%)\n0 (0.0%)\n\n\n3\nACT [integer]\n\n\n\nMean (sd) : 24.2 (2.8)\n\n\nmin ≤ med ≤ max:\n\n\n16 ≤ 24 ≤ 33\n\n\nIQR (CV) : 4 (0.1)\n\n\n\n15 distinct values\n\n141 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-18\n\n\n\n\n\n\nSe grafican la relación entre las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus regresiones simples. A su vez, se grafica un tercer gráfico que muestra la correlación entre las variables independientes.\n\n#Grafico x1 = ACT y= colGPA\ngact &lt;- ggscatter(gpa1, x = \"ACT\", y = \"colGPA\",\n          shape = 21, size = 3, # Forma y tamaño de puntos\n   add = \"reg.line\", #Agregar recta de regresion\n   cor.coef = TRUE)# Agregar coeficiente correlacion\n#Grafico x2 = hsGPA y= colGPA\nghsGPA &lt;- ggscatter(gpa1, x = \"hsGPA\", y = \"colGPA\",\n          shape = 21, size = 3,\n   add = \"reg.line\",\n   cor.coef = TRUE)\n\n#Grafico x2 = hsGPA x1 = ACT\ngact_hs &lt;- ggscatter(gpa1, x = \"hsGPA\", y = \"ACT\",\n          shape = 21, size = 3,\n   add = \"reg.line\",\n   cor.coef = TRUE)\n\ngrid.arrange(gact, ghsGPA, gact_hs, nrow = 1) # Unir graficos\n\n\n\n\n\n\n\n\nCon el gráfico anterior podemos notar dos puntos relevantes:\n\nSi bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\nComo es de esperar, existe una relación entre las calificaciones en la enseñanza media (\\(hsGPA\\)) y el puntaje en la prueba de admisión (\\(ACT\\)). Específicamente, ambas variables tienen una asociación positiva de 0.35.\n\nEn la práctica 5 nos preguntamos ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?, sin profundizar en qué implica que nuestros predictores de \\(colGPA\\) estén correlacionados. Retomemos nuevamente nuestro modelo\n\n\n\nPara estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\n\nRegresión múltiple  modelo &lt;- lm(y ~ x1 + x2 , data = data)\n\nPor fines de comparación, se estimaran primero dos regresiones simples con cada predictor, y luego la regresión múltiple en el Modelo 3:\n\ncol_actmodel&lt;-lm(colGPA ~ ACT, data=gpa1)\ncol_hsmodel&lt;-lm(colGPA ~  hsGPA, data=gpa1)\ncol_model &lt;- lm(colGPA ~ ACT + hsGPA, data = gpa1)\n\n\nsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \"stars\", dv.labels = c(\"Modelo 1\", \"Modelo 2\", \"Modelo 3\"),string.pred = \"Predictores\", string.est = \"β\")\n\n\n\n\n \nModelo 1\nModelo 2\nModelo 3\n\n\nPredictores\nβ\nβ\nβ\n\n\n(Intercept)\n2.40 ***\n1.42 ***\n1.29 ***\n\n\nACT\n0.03 *\n\n0.01 \n\n\nhsGPA\n\n0.48 ***\n0.45 ***\n\n\nObservations\n141\n141\n141\n\n\nR2 / R2 adjusted\n0.043 / 0.036\n0.172 / 0.166\n0.176 / 0.164\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\n\\[\\widehat{colGPA} = 1.29 +0.01 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]\n\n\n\n¿Cómo se interpreta este cuadro con los 3 modelos de regresión?\nEl modelo 1 estima que por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.03 puntos.\nEl modelo 2 estima que por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.48 puntos.\nEl modelo 3 estima \\(colGPA\\) considerando en conjunto ambas variables. Por un lado, por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.01 puntos, manteniendo \\(hsGPA\\) constante Por otro, por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.45 puntos, manteniendo \\(ACT\\) constante.\n\n\nComo vimos en los gráficos de dispersión, existe una correlación entre nuestros predictores: el puntaje en \\(ACT\\) está asociado con las notas de enseñanza media \\(hsGPA\\).\nCuando se incorporan más variables en el modelo se descuenta este elemento en común que tienen las variables independientes. Por ello no solo los coefientes de regresión se ajustan en presencia de otras variables (\\(hsGPA\\) disminuyó de 0.48 a 0.45 y \\(ACT\\) de 0.03 a 0.01), sino que también el ajuste del modelo cambia (\\(R^2ajustado\\) es el estadístico más óptimo para identificar ello, pues como vimos en la práctica 5 \\(R^2\\) sobreestima la bondad de ajuste).\n\n\n\n\nLa forma de hacer este procedimiento de “mantener constante” el efecto de la otra variable se llama parcialización. Este procedimiento implica sacar la covarianza común entre mis variables independientes, es decir, lo que tienen en común \\(hsGPA\\) y \\(ACT\\)\nSe habla de efectos parciales porque se estiman las regresiones solo con una de las variables independientes. Por ejemplo, ¿Cómo se predice \\(colGPA\\) en función \\(ACT\\), despejando el efecto de \\(hsGPA\\)?\nEn fórmula podemos ver que las estimaciones de $ b_{1}$ y $ b_{2}$ se interpretan como efectos parciales, de manera que dados los cambios en \\(ACT\\) y \\(hsGPA\\) se puede obtener un cambio predicho para \\(colGPA\\).\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} + b_{2}\\triangle{hsGPA} \\]\nPero cuando \\(hsGPA\\) se mantiene constante, de manera que \\(\\triangle{hsGPA}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} \\]\nPero cuando \\(ACT\\) se mantiene constante, de manera que \\(\\triangle{ACT}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} =  b_{2}\\triangle{hsGPA} \\]\n\n\n¿Cómo determinar cuál es el (a) elemento común entre ambas variables y (b) extraer solamente aquello que no comparten?\nPara ello se realiza (a) una regresión simple donde los predictores son las variables del modelo (\\(ACT\\) dependiente y \\(hsGPA\\) independiente) y (b) en donde a la predicción de \\(ACT\\) hay asociado un residuo.\nEn otras palabras, el \\(b\\) de esta regresión es todo lo que comparte \\(ACT\\) y \\(hsGPA\\). Mientras que el residuo es todo lo de \\(ACT\\) que no es explicado por \\(hsGPA\\). En síntesis, es con lo que nos deberíamos quedar en nuestros modelos de regresión múltiple al estimar el \\(b_{1}\\) de \\(ACT\\).\n\n\n\nmodel_act_hs = lm(ACT ~ hsGPA, data = gpa1) #Crear regresion con predictores\ncoef(model_act_hs)\n\n(Intercept)       hsGPA \n  13.696763    3.074331 \n\n\nEn consecuencia tenemos que \\[\\widehat{ACT} = 13.69 + 3.07{hsGPA} \\]\n\n\n\nSabemos que si tenemos un modelo de regresión podemos también obtener los residuos. Recordemos ¿qué es un residuo? Un residuo es la diferencia entre el valor observado y el valor predicho\n\nfit_act_hs=fitted.values(model_act_hs) # Calcular valores predichos\nres_act_hs=residuals(model_act_hs) #Calcular residuos\ngpa1=cbind(gpa1, fit_act_hs,res_act_hs) # Unir columna de residuos y valores predichos a base de datos\nhead(gpa1) #Mostrar los primeros elementos de la base de datos\n\n  colGPA hsGPA ACT fit_act_hs res_act_hs\n1    3.0   3.0  21   22.91975 -1.9197550\n2    3.4   3.2  24   23.53462  0.4653787\n3    3.0   3.6  26   24.76435  1.2356469\n4    3.5   3.5  27   24.45692  2.5430797\n5    3.6   3.9  28   25.68665  2.3133472\n6    3.0   3.4  25   24.14949  0.8505125\n\n\nPodemos ver en res_act_hs la varianza no explicada de \\(hsGPA\\) sobre \\(ACT\\).\n\n\n\nAhora si hacemos la regresión con la variable res_act_hs notaremos que obtendremos el mismo \\(b_{1}\\) de la regresión del modelo múltiple (modelo 3) pero por medio de una regresión simple (modelo 4).\n\nact_hs_model &lt;- lm(colGPA ~ res_act_hs, data = gpa1) # Estimar regresión simple con parcialización de ACT\n\n\nsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model, act_hs_model), show.ci=FALSE, p.style = \"stars\", dv.labels = c(\"Modelo 1\", \"Modelo 2\", \"Modelo 3\", \"Modelo 4\"),string.pred = \"Predictores\", string.est = \"β\")\n\n\n\n\n \nModelo 1\nModelo 2\nModelo 3\nModelo 4\n\n\nPredictores\nβ\nβ\nβ\nβ\n\n\n(Intercept)\n2.40 ***\n1.42 ***\n1.29 ***\n3.06 ***\n\n\nACT\n0.03 *\n\n0.01 \n\n\n\nhsGPA\n\n0.48 ***\n0.45 ***\n\n\n\nres act hs\n\n\n\n0.01 \n\n\nObservations\n141\n141\n141\n141\n\n\nR2 / R2 adjusted\n0.043 / 0.036\n0.172 / 0.166\n0.176 / 0.164\n0.005 / -0.003\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nLo que tengo en ese modelo es la variable puntaje en el examen de admisión \\(ACT\\) sin las notas de enseñanza media \\(hsGPA\\). Lo mismo se podría realizar con la parcialización de \\(hsGPA\\).\nEste procedimiento de extraer el elemento común entre las variables es el que hace “tras bambalinas” la regresión múltiple. Lo importante es notar que en la regresión múltiple todos los predictores están parcializados del resto de los predictores. Se han “limpiado” de los efectos de las otras variables el resto de las variables del modelo.\n\n\n\n\n\n¿En cuál variable me fijo para la interpretación? Podemos graficar los coeficientes de la regresión de modo de ver el impacto que tienen cada una de las variables sobre \\(colGPA\\)\n\nplot_model(col_model, show.values = TRUE)+ theme_sjplot()\n\n\n\n\n\n\n\n\nComo podemos ver el efecto que tiene \\(hsGPA\\) sobre \\(colGPA\\), controlando por \\(ACT\\), es mucho mayor que el que tiene \\(ACT\\) parcializado por \\(colGPA\\). Sin embargo, esto nada nos dice de qué variable enfatizar: esto dependen de las hipótesis que queremos probar con nuestros modelos.\n\n\n\nEn la interpretación del modelo vimos que los coeficientes de regresión nos permiten entender el efecto de \\(ACT\\) sobre \\(colGPA\\), manteniendo \\(hsGPA\\) constante. También, \\(hsGPA\\) sobre \\(colGPA\\), manteniendo \\(ACT\\) constante.\nLa regresión múltiple nos proporciona esta interpretación “manteniendo constante las variables”, incluso cuando en nuestros mismos datos no hayan sido recolectados considerando que algunas variables se mantengan constantes. Esto es lo que hemos llamado una interpretación de efecto parcial de los coeficientes de regresión. Esto no implica que se haya encuestado personas con el mismo \\(hsGPA\\) pero con puntuaciones en \\(ACT\\). Para obtener los datos no se pusieron restricciones sobre los valores muestrales de \\(hsGPA\\) o de \\(ACT\\). Más bien, la regresión múltiple permite imitar esta situación “constante” sin restringir los valores de ninguna de las variables independientes.",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#librerías",
    "href": "practicos/practico-02.html#librerías",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "pacman::p_load(ggpubr, #graficos\n               dplyr, #manipulacion de datos\n               sjPlot, #tablas\n               gridExtra, #unir graficos\n               texreg, #mostrar regresion multiple\n               summarytools, #estadisticos descriptivos\n               wooldridge) #paquete con los ejemplos del libro\nlibrary(wooldridge)",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#datos",
    "href": "practicos/practico-02.html#datos",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "Los datos a utilizar corresponden a la base de datos gpa1 que incluye una muestra de 141 estudiantes de una universidad. La base contiene variables:\n\n\\(colGPA\\): promedio general de calificaciones de la universidad, en escala de 0 a 4 puntos.\n\\(hsGPA\\) : promedio general de calificaciones en la enseñanza media, en escala de 0 a 4 puntos\n\\(ACT\\) : puntaje en el examen de admisión a la universidad, que va de 16 a 33 puntos\n\nPrimero, se cargará la base de datos que contiene la librería wooldrige y se seleccionarán las variables señaladas\n\ndata('gpa1') # Cargar base de datos\ngpa1 &lt;- dplyr::select(gpa1, colGPA, hsGPA, ACT) #Seleccion de variables",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#explorar-base-de-datos",
    "href": "practicos/practico-02.html#explorar-base-de-datos",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "A partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\n\nview(dfSummary(gpa1, headings = FALSE, method = \"render\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\ncolGPA [numeric]\n\n\n\nMean (sd) : 3.1 (0.4)\n\n\nmin ≤ med ≤ max:\n\n\n2.2 ≤ 3 ≤ 4\n\n\nIQR (CV) : 0.5 (0.1)\n\n\n\n19 distinct values\n\n141 (100.0%)\n0 (0.0%)\n\n\n2\nhsGPA [numeric]\n\n\n\nMean (sd) : 3.4 (0.3)\n\n\nmin ≤ med ≤ max:\n\n\n2.4 ≤ 3.4 ≤ 4\n\n\nIQR (CV) : 0.4 (0.1)\n\n\n\n16 distinct values\n\n141 (100.0%)\n0 (0.0%)\n\n\n3\nACT [integer]\n\n\n\nMean (sd) : 24.2 (2.8)\n\n\nmin ≤ med ≤ max:\n\n\n16 ≤ 24 ≤ 33\n\n\nIQR (CV) : 4 (0.1)\n\n\n\n15 distinct values\n\n141 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-18",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#relacion-entre-variables",
    "href": "practicos/practico-02.html#relacion-entre-variables",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "Se grafican la relación entre las variables que determinarían \\(colGPA\\) para comparar sus distribuciones y sus pendientes (\\(b\\)) de sus regresiones simples. A su vez, se grafica un tercer gráfico que muestra la correlación entre las variables independientes.\n\n#Grafico x1 = ACT y= colGPA\ngact &lt;- ggscatter(gpa1, x = \"ACT\", y = \"colGPA\",\n          shape = 21, size = 3, # Forma y tamaño de puntos\n   add = \"reg.line\", #Agregar recta de regresion\n   cor.coef = TRUE)# Agregar coeficiente correlacion\n#Grafico x2 = hsGPA y= colGPA\nghsGPA &lt;- ggscatter(gpa1, x = \"hsGPA\", y = \"colGPA\",\n          shape = 21, size = 3,\n   add = \"reg.line\",\n   cor.coef = TRUE)\n\n#Grafico x2 = hsGPA x1 = ACT\ngact_hs &lt;- ggscatter(gpa1, x = \"hsGPA\", y = \"ACT\",\n          shape = 21, size = 3,\n   add = \"reg.line\",\n   cor.coef = TRUE)\n\ngrid.arrange(gact, ghsGPA, gact_hs, nrow = 1) # Unir graficos\n\n\n\n\n\n\n\n\nCon el gráfico anterior podemos notar dos puntos relevantes:\n\nSi bien ambas variables tienen una asociación positiva con \\(colGPA\\), el tamaño efecto de esta relación es distinta. Incluso, \\(hsGPA\\) que no había sido considerada en nuestro modelo inicial, tiene una asociación más grande con nuestra variable dependiente.\nComo es de esperar, existe una relación entre las calificaciones en la enseñanza media (\\(hsGPA\\)) y el puntaje en la prueba de admisión (\\(ACT\\)). Específicamente, ambas variables tienen una asociación positiva de 0.35.\n\nEn la práctica 5 nos preguntamos ¿cómo incide \\(ACT\\) y \\(hsGPA\\) en conjunto sobre \\(colGPA\\)?, sin profundizar en qué implica que nuestros predictores de \\(colGPA\\) estén correlacionados. Retomemos nuevamente nuestro modelo",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#modelo-de-regresión-multiple",
    "href": "practicos/practico-02.html#modelo-de-regresión-multiple",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "Para estimar el modelo de regresión multiple se debe realizar el mismo procedimiento de la regresión simple, solo que ahora deben señalar un (+) y el segundo predictor\n\nRegresión múltiple  modelo &lt;- lm(y ~ x1 + x2 , data = data)\n\nPor fines de comparación, se estimaran primero dos regresiones simples con cada predictor, y luego la regresión múltiple en el Modelo 3:\n\ncol_actmodel&lt;-lm(colGPA ~ ACT, data=gpa1)\ncol_hsmodel&lt;-lm(colGPA ~  hsGPA, data=gpa1)\ncol_model &lt;- lm(colGPA ~ ACT + hsGPA, data = gpa1)\n\n\nsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model), show.ci=FALSE, p.style = \"stars\", dv.labels = c(\"Modelo 1\", \"Modelo 2\", \"Modelo 3\"),string.pred = \"Predictores\", string.est = \"β\")\n\n\n\n\n \nModelo 1\nModelo 2\nModelo 3\n\n\nPredictores\nβ\nβ\nβ\n\n\n(Intercept)\n2.40 ***\n1.42 ***\n1.29 ***\n\n\nACT\n0.03 *\n\n0.01 \n\n\nhsGPA\n\n0.48 ***\n0.45 ***\n\n\nObservations\n141\n141\n141\n\n\nR2 / R2 adjusted\n0.043 / 0.036\n0.172 / 0.166\n0.176 / 0.164\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\n\\[\\widehat{colGPA} = 1.29 +0.01 \\dot\\ ACT + 0.453\\dot\\ hsGPA \\]",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#interpretación",
    "href": "practicos/practico-02.html#interpretación",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "¿Cómo se interpreta este cuadro con los 3 modelos de regresión?\nEl modelo 1 estima que por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.03 puntos.\nEl modelo 2 estima que por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.48 puntos.\nEl modelo 3 estima \\(colGPA\\) considerando en conjunto ambas variables. Por un lado, por cada punto que aumenta el examen de admisión \\(ACT\\), \\(colGPA\\) aumentaráen 0.01 puntos, manteniendo \\(hsGPA\\) constante Por otro, por cada punto que aumenta las notas en enseñanza media \\(hsGPA\\), \\(colGPA\\) aumentará en 0.45 puntos, manteniendo \\(ACT\\) constante.\n\n\nComo vimos en los gráficos de dispersión, existe una correlación entre nuestros predictores: el puntaje en \\(ACT\\) está asociado con las notas de enseñanza media \\(hsGPA\\).\nCuando se incorporan más variables en el modelo se descuenta este elemento en común que tienen las variables independientes. Por ello no solo los coefientes de regresión se ajustan en presencia de otras variables (\\(hsGPA\\) disminuyó de 0.48 a 0.45 y \\(ACT\\) de 0.03 a 0.01), sino que también el ajuste del modelo cambia (\\(R^2ajustado\\) es el estadístico más óptimo para identificar ello, pues como vimos en la práctica 5 \\(R^2\\) sobreestima la bondad de ajuste).",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#parcialización",
    "href": "practicos/practico-02.html#parcialización",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "La forma de hacer este procedimiento de “mantener constante” el efecto de la otra variable se llama parcialización. Este procedimiento implica sacar la covarianza común entre mis variables independientes, es decir, lo que tienen en común \\(hsGPA\\) y \\(ACT\\)\nSe habla de efectos parciales porque se estiman las regresiones solo con una de las variables independientes. Por ejemplo, ¿Cómo se predice \\(colGPA\\) en función \\(ACT\\), despejando el efecto de \\(hsGPA\\)?\nEn fórmula podemos ver que las estimaciones de $ b_{1}$ y $ b_{2}$ se interpretan como efectos parciales, de manera que dados los cambios en \\(ACT\\) y \\(hsGPA\\) se puede obtener un cambio predicho para \\(colGPA\\).\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} + b_{2}\\triangle{hsGPA} \\]\nPero cuando \\(hsGPA\\) se mantiene constante, de manera que \\(\\triangle{hsGPA}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} = b_{1}\\triangle{ACT} \\]\nPero cuando \\(ACT\\) se mantiene constante, de manera que \\(\\triangle{ACT}\\) = 0, se obtiene entonces:\n\\[\\triangle{colGPA} =  b_{2}\\triangle{hsGPA} \\]\n\n\n¿Cómo determinar cuál es el (a) elemento común entre ambas variables y (b) extraer solamente aquello que no comparten?\nPara ello se realiza (a) una regresión simple donde los predictores son las variables del modelo (\\(ACT\\) dependiente y \\(hsGPA\\) independiente) y (b) en donde a la predicción de \\(ACT\\) hay asociado un residuo.\nEn otras palabras, el \\(b\\) de esta regresión es todo lo que comparte \\(ACT\\) y \\(hsGPA\\). Mientras que el residuo es todo lo de \\(ACT\\) que no es explicado por \\(hsGPA\\). En síntesis, es con lo que nos deberíamos quedar en nuestros modelos de regresión múltiple al estimar el \\(b_{1}\\) de \\(ACT\\).\n\n\n\nmodel_act_hs = lm(ACT ~ hsGPA, data = gpa1) #Crear regresion con predictores\ncoef(model_act_hs)\n\n(Intercept)       hsGPA \n  13.696763    3.074331 \n\n\nEn consecuencia tenemos que \\[\\widehat{ACT} = 13.69 + 3.07{hsGPA} \\]\n\n\n\nSabemos que si tenemos un modelo de regresión podemos también obtener los residuos. Recordemos ¿qué es un residuo? Un residuo es la diferencia entre el valor observado y el valor predicho\n\nfit_act_hs=fitted.values(model_act_hs) # Calcular valores predichos\nres_act_hs=residuals(model_act_hs) #Calcular residuos\ngpa1=cbind(gpa1, fit_act_hs,res_act_hs) # Unir columna de residuos y valores predichos a base de datos\nhead(gpa1) #Mostrar los primeros elementos de la base de datos\n\n  colGPA hsGPA ACT fit_act_hs res_act_hs\n1    3.0   3.0  21   22.91975 -1.9197550\n2    3.4   3.2  24   23.53462  0.4653787\n3    3.0   3.6  26   24.76435  1.2356469\n4    3.5   3.5  27   24.45692  2.5430797\n5    3.6   3.9  28   25.68665  2.3133472\n6    3.0   3.4  25   24.14949  0.8505125\n\n\nPodemos ver en res_act_hs la varianza no explicada de \\(hsGPA\\) sobre \\(ACT\\).\n\n\n\nAhora si hacemos la regresión con la variable res_act_hs notaremos que obtendremos el mismo \\(b_{1}\\) de la regresión del modelo múltiple (modelo 3) pero por medio de una regresión simple (modelo 4).\n\nact_hs_model &lt;- lm(colGPA ~ res_act_hs, data = gpa1) # Estimar regresión simple con parcialización de ACT\n\n\nsjPlot::tab_model(list(col_actmodel, col_hsmodel,col_model, act_hs_model), show.ci=FALSE, p.style = \"stars\", dv.labels = c(\"Modelo 1\", \"Modelo 2\", \"Modelo 3\", \"Modelo 4\"),string.pred = \"Predictores\", string.est = \"β\")\n\n\n\n\n \nModelo 1\nModelo 2\nModelo 3\nModelo 4\n\n\nPredictores\nβ\nβ\nβ\nβ\n\n\n(Intercept)\n2.40 ***\n1.42 ***\n1.29 ***\n3.06 ***\n\n\nACT\n0.03 *\n\n0.01 \n\n\n\nhsGPA\n\n0.48 ***\n0.45 ***\n\n\n\nres act hs\n\n\n\n0.01 \n\n\nObservations\n141\n141\n141\n141\n\n\nR2 / R2 adjusted\n0.043 / 0.036\n0.172 / 0.166\n0.176 / 0.164\n0.005 / -0.003\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nLo que tengo en ese modelo es la variable puntaje en el examen de admisión \\(ACT\\) sin las notas de enseñanza media \\(hsGPA\\). Lo mismo se podría realizar con la parcialización de \\(hsGPA\\).\nEste procedimiento de extraer el elemento común entre las variables es el que hace “tras bambalinas” la regresión múltiple. Lo importante es notar que en la regresión múltiple todos los predictores están parcializados del resto de los predictores. Se han “limpiado” de los efectos de las otras variables el resto de las variables del modelo.",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#control-estadístico",
    "href": "practicos/practico-02.html#control-estadístico",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "¿En cuál variable me fijo para la interpretación? Podemos graficar los coeficientes de la regresión de modo de ver el impacto que tienen cada una de las variables sobre \\(colGPA\\)\n\nplot_model(col_model, show.values = TRUE)+ theme_sjplot()\n\n\n\n\n\n\n\n\nComo podemos ver el efecto que tiene \\(hsGPA\\) sobre \\(colGPA\\), controlando por \\(ACT\\), es mucho mayor que el que tiene \\(ACT\\) parcializado por \\(colGPA\\). Sin embargo, esto nada nos dice de qué variable enfatizar: esto dependen de las hipótesis que queremos probar con nuestros modelos.",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#qué-significa-mantener-todos-los-demás-factores-constantes",
    "href": "practicos/practico-02.html#qué-significa-mantener-todos-los-demás-factores-constantes",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "",
    "text": "En la interpretación del modelo vimos que los coeficientes de regresión nos permiten entender el efecto de \\(ACT\\) sobre \\(colGPA\\), manteniendo \\(hsGPA\\) constante. También, \\(hsGPA\\) sobre \\(colGPA\\), manteniendo \\(ACT\\) constante.\nLa regresión múltiple nos proporciona esta interpretación “manteniendo constante las variables”, incluso cuando en nuestros mismos datos no hayan sido recolectados considerando que algunas variables se mantengan constantes. Esto es lo que hemos llamado una interpretación de efecto parcial de los coeficientes de regresión. Esto no implica que se haya encuestado personas con el mismo \\(hsGPA\\) pero con puntuaciones en \\(ACT\\). Para obtener los datos no se pusieron restricciones sobre los valores muestrales de \\(hsGPA\\) o de \\(ACT\\). Más bien, la regresión múltiple permite imitar esta situación “constante” sin restringir los valores de ninguna de las variables independientes.",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#predictores-dicotómicos",
    "href": "practicos/practico-02.html#predictores-dicotómicos",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "Predictores dicotómicos",
    "text": "Predictores dicotómicos\nLas variables dicotómicas son aquellas variables nominales u ordinales que poseen solo dos categorías de respuesta, por ejemplo hombre/mujer, sano/enfermo, deportista/sedentario.\nLa inclusión de estas variables en un modelo de regresión no requiere un tratamiento especial, solo hay que considerar que su interpretación tiene un sentido distinto. A continuación, veremos un ejemplo respecto a cómo predictores categóricos (de dos o más niveles) permiten modelar el Estatus Social Subjetivo",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#librerías-1",
    "href": "practicos/practico-02.html#librerías-1",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "Librerías",
    "text": "Librerías\n\npacman::p_load(dplyr, #manipulacion de datos\n               sjPlot, #tablas\n               summarytools, #estadisticos descriptivos\n               fastDummies, # Crear variable dummy\n               sjlabelled, #etiquetas variables\n               coefplot # graficos de coeficientes\n               )",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#datos-1",
    "href": "practicos/practico-02.html#datos-1",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "Datos",
    "text": "Datos\nPrimero, se cargará la base de datos\n\nload(url(\"https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess.RData\")) # Cargar base de datos\n\nLos datos a utilizar corresponden a la base de datos ELSOC 2018 que incluye una muestra de 3784 mujeres y hombres adultos entre 18 y 75 años.\nVariables\n\n[ess]: “Estatus Social Subjetivo: Donde se ubicaria ud. en la sociedad chilena” (0 = el nivel mas bajo; 10 = el nivel mas alto)\n[edcine]: ¿Cuál es su nivel educacional? Indique el tipo de estudio actual (si estudia actualmente) o el último tipo aprobado (si no estudia actualmente) - CINE 2011 (UNESCO).\n\n[edad]: ¿Cuáles su edad? (años cumplidos).\n\n\nview_df(elsoc_18,encoding = \"\")\n\n\nData frame: elsoc_18\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ness\nEstatus Social Subjetivo\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n0 El nivel mas bajo\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10 El nivel mas alto\n\n\n2\nsexo\nSexo (1=Mujer)\n0\n1\nHombre\nMujer\n\n\n3\nedad\nEdad\nrange: 18-90\n\n\n4\nedcine\nEducación\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#explorar-base-de-datos-1",
    "href": "practicos/practico-02.html#explorar-base-de-datos-1",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "Explorar base de datos",
    "text": "Explorar base de datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para la interpretación de nuestros modelos.\n\nview(dfSummary(elsoc_18, headings = FALSE, method = \"render\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\ness [numeric]\nEstatus Social Subjetivo\n\n\n\nMean (sd) : 4.4 (1.6)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 5 ≤ 10\n\n\nIQR (CV) : 1 (0.4)\n\n\n\n11 distinct values\n\n3703 (100.0%)\n0 (0.0%)\n\n\n2\nsexo [numeric]\nSexo (1=Mujer)\n\n\n\nMin : 0\n\n\nMean : 0.4\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n2277\n(\n61.5%\n)\n\n\n1\n:\n1426\n(\n38.5%\n)\n\n\n\n\n3703 (100.0%)\n0 (0.0%)\n\n\n3\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 47 (15.5)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 47 ≤ 90\n\n\nIQR (CV) : 25 (0.3)\n\n\n\n70 distinct values\n\n3703 (100.0%)\n0 (0.0%)\n\n\n4\nedcine [numeric]\nEducación\n\n\n\nMean (sd) : 3.2 (1.2)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 3 ≤ 5\n\n\nIQR (CV) : 1 (0.4)\n\n\n\n\n\n\n1\n:\n442\n(\n11.9%\n)\n\n\n2\n:\n365\n(\n9.9%\n)\n\n\n3\n:\n1589\n(\n42.9%\n)\n\n\n4\n:\n592\n(\n16.0%\n)\n\n\n5\n:\n715\n(\n19.3%\n)\n\n\n\n\n3703 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-18",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#relación-entre-variables",
    "href": "practicos/practico-02.html#relación-entre-variables",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "Relación entre variables",
    "text": "Relación entre variables\nVisualizar la asociación entre variables puede ser informativo. Sin embargo, en ocasiones es necesario prestar mayor atención al tipo de gráfico que utilizamos para esto. Por ejemplo, veamos un scatter de Estatus social Subjetivo \\(Y_\\text{estatus}\\) con sexo como independiente \\(X_\\text{sexo}\\) para comparar sus distribuciones y sus pendientes\n\nplot_scatter(data = elsoc_18,x = sexo,y = ess,fit.grps = \"lm\")\n\n\n\n\n\n\n\n\nEl scatterplot no es muy informativo debido a que nuestra variable independiente solamente posee dos niveles, de modo tal que la distribución de Estatus Social Subjetivo se separa en dos grandes grupos. Por esta razón, una alternativa para visualizar la distribución es elaborar un gráfico de cajas para ambas categorías:\n\nplot_grpfrq(var.cnt = elsoc_18$ess,var.grp = elsoc_18$sexo,type = \"box\")\n\n\n\n\n\n\n\n\nEn este sentido, al tener solamente dos niveles en los valores de la variable X: 0 (Hombre) y 1 (Mujer). Obtenemos solamente dos medias condicionales.\nEntonces, si calculamos el promedio simple para Estatus Social Subjetivo por sexo tenemos:\n\nelsoc_18 %&gt;%\n  group_by(sexo) %&gt;%\n  summarise(mean_ess=mean(ess,na.rm = T))\n\n# A tibble: 2 × 2\n   sexo mean_ess\n  &lt;dbl&gt;    &lt;dbl&gt;\n1     0     4.34\n2     1     4.47\n\n\nSegun esto el promedio para las mujeres es de 4.47 puntos en la escala de Estatus Social Subjetivo, mientras para los hombres es de 4.34.\nRealizando ahora la regresión:\n\nreg1&lt;-lm(ess ~ sexo, data=elsoc_18)\n\n\nsjPlot::tab_model(list(reg1), show.ci=FALSE, p.style = \"stars\",string.pred = \"Predictores\", string.est = \"β\",digits = 3,\n                  dv.labels = c(\"Modelo 1\"))\n\n\n\n\n \nModelo 1\n\n\nPredictores\nβ\n\n\n(Intercept)\n4.339 ***\n\n\nSexo(1=Mujer)\n0.133 *\n\n\nObservations\n3703\n\n\nR2 / R2 adjusted\n0.002 / 0.001\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nEntonces:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + \\beta_1 \\times \\text{Sexo} + \\epsilon \\] Tenemos que las mujeres (Sexo = 1) tienen un promedio 0.133 puntos más alto que los hombres (Sexo = 0) en la escala de estatus social subjetivo. En este caso, el grupo de los hombres corresponde a la categoría de referencia.\nPor lo tanto, ¿cuál es la predicción de estatus social subjetivo para la variable sexo?\nPara el caso de los hombres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 0 = 4.339\\] En cambio, para las mujeres tenemos:\n\\[\\widehat{Y}_\\text{estatus} = 4.339 + 0.133 \\times 1 = 4.472\\]\nEntonces cuando calculamos el promedio de Estatus social Subjetivo \\(Y_\\text{estatus}\\) para hombre (\\(X_\\text{sexo=0}\\)) mujer (\\(X_\\text{sexo=1}\\)), podemos observar que son los mismos valores que nos entrega la estimación de la regresión simple empleando Sexo como predictor de Estatus Social Subjetivo. Es decir:\n\nAl ingresar un regresor dicotómico en regresión simple lo que se obtiene es una estimación de la diferencia de promedios de ambas categorías en relación a la variable dependiente -en regresión múltiple esta diferencia se ajusta o controla por la presencia de otras variables, por ejemplo:\n\n\nreg2&lt;-lm(ess ~ sexo+edad, data=elsoc_18)\n\n\nsjPlot::tab_model(list(reg1,reg2), show.ci=FALSE, p.style = \"stars\",string.pred = \"Predictores\", string.est = \"β\",digits = 3,\n                  dv.labels = c(\"Modelo 1\", \"Modelo 2\"))\n\n\n\n\n \nModelo 1\nModelo 2\n\n\nPredictores\nβ\nβ\n\n\n(Intercept)\n4.339 ***\n4.602 ***\n\n\nSexo(1=Mujer)\n0.133 *\n0.126 *\n\n\nEdad\n\n-0.006 ***\n\n\nObservations\n3703\n3703\n\n\nR2 / R2 adjusted\n0.002 / 0.001\n0.005 / 0.004\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\n\\[\\widehat{Y}_\\text{estatus} = 4.602 + 0.126 \\times \\text{Sexo} + -0.006 \\times \\text{Edad} + \\epsilon \\] Al controlar por la edad de las personas, las mujeres tienen un promedio 0.126 más alto que el de los hombres en la escala de Estatus Social Subjetivo. Vemos que, en comparación con el Modelo 1, la diferencia en el promedio de estatus subjetivo de mujeres respecto de hombres se ajusta al incorporar la edad. En este sentido, ¿por qué la diferencia en el promedio de estatus subjetivo entre mujeres y hombres puede verse afectada por la edad?. Revisemos el promedio de Edad para hombres y mujeres:\n\nelsoc_18 %&gt;%\n  group_by(sexo) %&gt;%\n  summarise(mean_ess=mean(edad,na.rm = T))\n\n# A tibble: 2 × 2\n   sexo mean_ess\n  &lt;dbl&gt;    &lt;dbl&gt;\n1     0     47.5\n2     1     46.3\n\n\nEsta información nos permite observar que los hombres tienen un promedio de edad de 1.2 años mayor que el de las mujeres. En este sentido, lo que vemos es que la diferencia promedio de estatus subjetivo entre hombres y mujeres disminuye de 0.136 a 0.126, es decir, se ajusta al considerar (controlar por) la edad de las personas.",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-02.html#predictores-con-más-de-una-categoría",
    "href": "practicos/practico-02.html#predictores-con-más-de-una-categoría",
    "title": "Práctico 02. Regresión lineal múltiple y predictores categóricos",
    "section": "Predictores con más de una categoría",
    "text": "Predictores con más de una categoría\nUna de las características de estatus más importante es el nivel educacional de las personas. En este sentido, el nivel educacional puede considerarse como una variable contínua (p.ej: años de educación) o categórica (nivel/grado educacional), lo cual depende no solo de la distribución empírica de la variable sino que también del criterio de quien investiga.\nPara este ejercicio consideraremos la variable educación en base a las categorías de la Clasificación Internacional Normalizada de la Educación (UNESCO). La cual posee 5 niveles:\n\nsjmisc::frq(x = elsoc_18$edcine,show.na = F)\n\nEducación (x) &lt;numeric&gt; \n# total N=3703 valid N=2988 mean=3.21 sd=1.21\n\nValue |                      Label |    N | Raw % | Valid % | Cum. %\n--------------------------------------------------------------------\n    1 |  Primaria incompleta menos |  442 | 11.94 |   11.94 |  11.94\n    2 | Primaria y secundaria baja |  365 |  9.86 |    9.86 |  21.79\n    3 |            Secundaria alta | 1589 | 42.91 |   42.91 |  64.70\n    4 |      Terciaria ciclo corto |  592 | 15.99 |   15.99 |  80.69\n    5 |      Terciaria y Postgrado |  715 | 19.31 |   19.31 | 100.00\n\n\nY se distribuye de esta manera:\n\nplot_frq(data = elsoc_18$edcine)\n\n\n\n\n\n\n\n\nPara poder incluir esta variable en la regresión como categórica en R la manera más simple es definirla como un factor. Primero necesitamos conocer la estructura de la variable, ya que puede venir previamente definida como factor:\n\nclass(elsoc_18$edcine)\n\n[1] \"numeric\"\n\nstr(elsoc_18$edcine)\n\n num [1:3703] 2 3 3 4 3 3 3 4 5 2 ...\n - attr(*, \"labels\")= Named num [1:5] 1 2 3 4 5\n  ..- attr(*, \"names\")= chr [1:5] \"Primaria incompleta menos\" \"Primaria y secundaria baja\" \"Secundaria alta\" \"Terciaria ciclo corto\" ...\n - attr(*, \"label\")= chr \"Educación\"\n\n\nVemos que al emplear class, R nos indica que edcine es una variable numérica con 5 valores distintos. Además, al correr str se nos indica que dichos valores numéricos poseen atributos en forma de etiquetas (labels). Entonces, si estimamos la regresión con la variable tal cual como está, obtenemos lo siguiente:\n\nreg3&lt;- lm(ess~edcine,data = elsoc_18)\n\n\nsjPlot::tab_model(list(reg3), show.ci=FALSE, p.style = \"stars\",string.pred = \"Predictores\", string.est = \"β\",digits = 3,\n                  dv.labels = c(\"Modelo 3\"))\n\n\n\n\n \nModelo 3\n\n\nPredictores\nβ\n\n\n(Intercept)\n3.329 ***\n\n\nEducación\n0.331 ***\n\n\nObservations\n3703\n\n\nR2 / R2 adjusted\n0.064 / 0.064\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nEl coeficiente de regresión nos indica que por cada nivel adicional de educación, hay un aumento de 0.331 puntos en la escala de estatus social subjetivo. Sin embargo, dada la naturaleza de nuestra variable, decir “por cada nivel educacional” es poco informativo, por lo tanto la manera más adecuada de utilizar nuestra variable en la estimación de una regresión es transformarla en un factor empleando la función as_factor()  De la librería sjlabelled .\n\nelsoc_18$edcine&lt;- as_factor(elsoc_18$edcine)\n\n\nNota: en R existe la función as.factor(), sin embargo, en esa ocasión usamos as_factor() debido a que es compatible los vectores numéricos etiquetados y nos permite matener todos los atributos de las variables, tales como las etiquetas de variable y valores.\n\nTeniendo nuestra variable transformada a factor, estimamos nuevamente la regresión:\n\nreg4 &lt;- lm(ess~edcine,data = elsoc_18)\n\n\nsjPlot::tab_model(list(reg3,reg4), show.ci=FALSE, p.style = \"stars\",string.pred = \"Predictores\", string.est = \"β\",digits = 3,\n                  dv.labels = c(\"Modelo 3\",\"Modelo 4\"))\n\n\n\n\n\n\n\n\n\n \nModelo 3\nModelo 4\n\n\nPredictores\nβ\nβ\n\n\n(Intercept)\n3.329 ***\n3.794 ***\n\n\nEducación\n0.331 ***\n\n\n\nEducación: Primaria y\nsecundaria baja\n\n0.151 \n\n\nEducación: Secundaria\nalta\n\n0.476 ***\n\n\nEducación: Terciaria\nciclo corto\n\n0.811 ***\n\n\nEducación: Terciaria y\nPostgrado\n\n1.279 ***\n\n\nObservations\n3703\n3703\n\n\nR2 / R2 adjusted\n0.064 / 0.064\n0.066 / 0.065\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\n\nInterpretación\nAl igual que en el modelo empleando Educación como variable continua, el modelo con Educación categórica muestra que a medida que aumenta el nivel educacional, el promedio de estatus subjetivo tiende a ser más alto. Por otro lado, en este caso la categoría de referencia es Primaria Incompleta o menos. Entonces:\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Primaria y Secundaria baja es 0.151 puntos más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Secundaria Alta es 0.476 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria ciclo corto es 0.811 más alto con respecto a las personas con educación Primaria Incompleta o menos.\nEl promedio en la escala de Estatus Social subjetivo para el grupo con educación Terciaria y Postgrado es de 1.279 más alto con respecto a las personas con educación Primaria Incompleta o menos.\n\nAlternativamente es posible cambiar la categoría de referencia. Por ejemplo, si quisieramos que la referencia fuera el nivel educativo más alto “Terciaria y Postgrado” (5) debemos usar relevel(edcine, ref =5):\n\n\nreg4.1 &lt;- lm(ess~relevel(edcine,ref=5),data = elsoc_18)\nsummary(reg4.1)\n\n\nCall:\nlm(formula = ess ~ relevel(edcine, ref = 5), data = elsoc_18)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0727 -0.7941  0.0548  0.7300  6.2059 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                5.07273    0.05710  88.833  &lt; 2e-16 ***\nrelevel(edcine, ref = 5)1 -1.27861    0.09239 -13.839  &lt; 2e-16 ***\nrelevel(edcine, ref = 5)2 -1.12752    0.09823 -11.479  &lt; 2e-16 ***\nrelevel(edcine, ref = 5)3 -0.80275    0.06876 -11.674  &lt; 2e-16 ***\nrelevel(edcine, ref = 5)4 -0.46800    0.08485  -5.516 3.71e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.527 on 3698 degrees of freedom\nMultiple R-squared:  0.06634,   Adjusted R-squared:  0.06533 \nF-statistic: 65.69 on 4 and 3698 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nVariables dummy\nLa manera tradicional de incluir predictores categóricos de más de dos niveles (variable politómica) es a través de las denominadas variables dummy. Tal como vimos en el ejemplo anterior, se incluyen n-1 categorías en el modelo dado que siempre se mantiene una como categoría de referencia.\nPara explorar nuestra base de datos, usaremos la función head() que nos mostrará las primeras 6 filas de nuestra base de datos para observar la variable Educación.\n\nhead(elsoc_18)\n\n  ess sexo edad edcine\n1   9    0   66      2\n2   5    0   62      3\n3   5    0   28      3\n4   5    1   53      4\n5   5    1   63      3\n6   5    0   56      3\n\n\nPara la construcción de las variables dummy, usaremos la función dummy_cols() de la librería fastDummies. En el argumento select_columns, le indicamos cuál es la variable que usaremos para construir las variables dummy:\n\nlibrary(fastDummies)\nelsoc_18 &lt;- dummy_cols(elsoc_18,select_columns = \"edcine\")\n\nRevisamos nuestra base de datos:\n\nhead(elsoc_18)\n\n  ess sexo edad edcine edcine_1 edcine_2 edcine_3 edcine_4 edcine_5\n1   9    0   66      2        0        1        0        0        0\n2   5    0   62      3        0        0        1        0        0\n3   5    0   28      3        0        0        1        0        0\n4   5    1   53      4        0        0        0        1        0\n5   5    1   63      3        0        0        1        0        0\n6   5    0   56      3        0        0        1        0        0\n\n\nTal como se estimó en el modelo anterior, ahora lo que haremos es seleccionar cada dummy para las categorías 2, 3, 4 y 5 de la variable edcine. Esto implica que el nivel 1 (Primaria incompleta o menos) será la categoría de referencia.\n\nreg5 &lt;- lm(ess~edcine_2+edcine_3+edcine_4+edcine_5,data = elsoc_18)\n\n\nsjPlot::tab_model(list(reg4, reg5), show.ci=FALSE, p.style = \"stars\",string.pred = \"Predictores\", string.est = \"β\",digits = 3,\n                  dv.labels = c(\"Modelo 4\",\"Modelo 5\"))\n\n\n\n\n\n\n\n\n\n \nModelo 4\nModelo 5\n\n\nPredictores\nβ\nβ\n\n\n(Intercept)\n3.794 ***\n3.794 ***\n\n\nEducación: Primaria y\nsecundaria baja\n0.151 \n\n\n\nEducación: Secundaria\nalta\n0.476 ***\n\n\n\nEducación: Terciaria\nciclo corto\n0.811 ***\n\n\n\nEducación: Terciaria y\nPostgrado\n1.279 ***\n\n\n\nedcine 2\n\n0.151 \n\n\nedcine 3\n\n0.476 ***\n\n\nedcine 4\n\n0.811 ***\n\n\nedcine 5\n\n1.279 ***\n\n\nObservations\n3703\n3703\n\n\nR2 / R2 adjusted\n0.066 / 0.065\n0.066 / 0.065\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nSi observamos la tabla de arriba, vemos que las estimaciones para el modelo 4 y 5 son idénticas. La única diferencia es que en el Modelo 5 empleamos dummies para cada categoría en vez de utilizar la variable como un factor.",
    "crumbs": [
      "Practicos",
      "Práctico 2 - Regresión lineal múltiple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html",
    "href": "practicos/practico-01.html",
    "title": "Práctico 01. Regresión lineal I",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de regresiones lineales en R.\n\n\n\nConfianza en vecinos con elsoc 2016.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#objetivo-de-la-práctica",
    "href": "practicos/practico-01.html#objetivo-de-la-práctica",
    "title": "Práctico 01. Regresión lineal I",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de regresiones lineales en R.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#antecedentes-de-los-datos-a-utilizar",
    "href": "practicos/practico-01.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Práctico 01. Regresión lineal I",
    "section": "",
    "text": "Confianza en vecinos con elsoc 2016.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#librerias",
    "href": "practicos/practico-01.html#librerias",
    "title": "Práctico 01. Regresión lineal I",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\n\npacman::p_load(dplyr,\n               haven, \n               car, \n               sjmisc, \n               sjPlot, \n               sjlabelled, \n               stargazer, \n               kableExtra, \n               corrplot, \n               ggplot2,\n               ggpubr)",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#cargar-base-de-datos",
    "href": "practicos/practico-01.html#cargar-base-de-datos",
    "title": "Práctico 01. Regresión lineal I",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\n\n#cargamos la base de datos desde internet\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 18035, 750 ).\n\ndim(elsoc_long_2016_2022.2) # dimension de la base\n\n[1] 18035   750",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#selección-de-variables-a-utilizar",
    "href": "practicos/practico-01.html#selección-de-variables-a-utilizar",
    "title": "Práctico 01. Regresión lineal I",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello lo más fácil es revisar el libro de códigos de cada base de datos. Además filtramos por la ola 1 para trabajar solo con datos del 2016.\n\nproc_data &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==\"1\") %&gt;% \n  select(t01, # Confianza en vecinos\n         m01,# nivel educacional\n         m0_sexo,# sexo\n         m0_edad# edad\n         )\n\n# Comprobar\nnames(proc_data)\n\n[1] \"t01\"     \"m01\"     \"m0_sexo\" \"m0_edad\"\n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                 t01                                  m01 \n\"Cuanto confia usted en sus vecinos\"                  \"Nivel educacional\" \n                             m0_sexo                              m0_edad \n             \"Sexo del entrevistado\"              \"Edad del entrevistado\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#procesamiento-de-variables",
    "href": "practicos/practico-01.html#procesamiento-de-variables",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Procesamiento de variables",
    "text": "Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\nConfianza en vecinos\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$t01)\n\nCuanto confia usted en sus vecinos (x) &lt;numeric&gt; \n# total N=2927 valid N=2927 mean=-2.78 sd=74.04\n\nValue |                                 Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------------\n -999 |                           No Responde |   5 |  0.17 |    0.17 |   0.17\n -888 |                               No Sabe |  14 |  0.48 |    0.48 |   0.65\n -777 |       Valor perdido por error tecnico |   0 |  0.00 |    0.00 |   0.65\n -666 | Valor perdido por encuesta incompleta |   0 |  0.00 |    0.00 |   0.65\n    1 |                              Muy poco | 332 | 11.34 |   11.34 |  11.99\n    2 |                                  Poco | 502 | 17.15 |   17.15 |  29.14\n    3 |                                  Algo | 713 | 24.36 |   24.36 |  53.50\n    4 |                              Bastante | 987 | 33.72 |   33.72 |  87.22\n    5 |                                 Mucho | 374 | 12.78 |   12.78 | 100.00\n &lt;NA&gt; |                                  &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-999) y “No sabe” (-888), (-777) y (-666) que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden correcto.\nb. Recodificación\nDespués de revisar el libro de códigos, no hay variables en que los valores negativos representen alguna otra característica, así que podemos usar set_na\n\nproc_data &lt;- proc_data %&gt;% set_na(., na = c(-999, -888, -777, -666))\n\n\nfrq(proc_data$t01)\n\nCuanto confia usted en sus vecinos (x) &lt;numeric&gt; \n# total N=2927 valid N=2908 mean=3.20 sd=1.20\n\nValue |    Label |   N | Raw % | Valid % | Cum. %\n-------------------------------------------------\n    1 | Muy poco | 332 | 11.34 |   11.42 |  11.42\n    2 |     Poco | 502 | 17.15 |   17.26 |  28.68\n    3 |     Algo | 713 | 24.36 |   24.52 |  53.20\n    4 | Bastante | 987 | 33.72 |   33.94 |  87.14\n    5 |    Mucho | 374 | 12.78 |   12.86 | 100.00\n &lt;NA&gt; |     &lt;NA&gt; |  19 |  0.65 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data &lt;- proc_data %&gt;% rename(\"confianza_vecinos\"=t01)\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nproc_data$confianza_vecinos &lt;- set_label(x = proc_data$confianza_vecinos,label = \"Confianza en vecinos\")\nget_label(proc_data$confianza_vecinos)\n\n[1] \"Confianza en vecinos\"\n\n\nRevisión final\nNuevamente un descriptivo de la variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$confianza_vecinos)\n\nConfianza en vecinos (x) &lt;numeric&gt; \n# total N=2927 valid N=2908 mean=3.20 sd=1.20\n\nValue |    Label |   N | Raw % | Valid % | Cum. %\n-------------------------------------------------\n    1 | Muy poco | 332 | 11.34 |   11.42 |  11.42\n    2 |     Poco | 502 | 17.15 |   17.26 |  28.68\n    3 |     Algo | 713 | 24.36 |   24.52 |  53.20\n    4 | Bastante | 987 | 33.72 |   33.94 |  87.14\n    5 |    Mucho | 374 | 12.78 |   12.86 | 100.00\n &lt;NA&gt; |     &lt;NA&gt; |  19 |  0.65 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Educación\n\n[m01] = Nivel de estudios alcanzado - Entrevistado\n\na. Descriptivo\n\nfrq(proc_data$m01)\n\nNivel educacional (x) &lt;numeric&gt; \n# total N=2927 valid N=2925 mean=5.26 sd=2.20\n\nValue |                                       Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------------------\n    1 |                                Sin estudios |  37 |  1.26 |    1.26 |   1.26\n    2 |  Educacion Basica o Preparatoria incompleta | 322 | 11.00 |   11.01 |  12.27\n    3 |    Educacion Basica o Preparatoria completa | 297 | 10.15 |   10.15 |  22.43\n    4 |    Educacion Media o Humanidades incompleta | 394 | 13.46 |   13.47 |  35.90\n    5 |      Educacion Media o Humanidades completa | 857 | 29.28 |   29.30 |  65.20\n    6 |                 Tecnica Superior incompleta | 102 |  3.48 |    3.49 |  68.68\n    7 |                   Tecnica Superior completa | 381 | 13.02 |   13.03 |  81.71\n    8 |                    Universitaria incompleta | 186 |  6.35 |    6.36 |  88.07\n    9 |                      Universitaria completa | 303 | 10.35 |   10.36 |  98.43\n   10 | Estudios de posgrado (magister o doctorado) |  46 |  1.57 |    1.57 | 100.00\n &lt;NA&gt; |                                        &lt;NA&gt; |   2 |  0.07 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEsta vez la vamos a dejar así\n\n\n\n4.3. Sexo\n\n[m0_sexo] = SEXO Sexo\n\na. Descriptivo\n\nfrq(proc_data$m0_sexo)\n\nSexo del entrevistado (x) &lt;numeric&gt; \n# total N=2927 valid N=2927 mean=1.60 sd=0.49\n\nValue |  Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    1 | Hombre | 1163 | 39.73 |   39.73 |  39.73\n    2 |  Mujer | 1764 | 60.27 |   60.27 | 100.00\n &lt;NA&gt; |   &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n4.4 Edad\n\n[m0_edad] = EDAD Edad.\n\na. Descriptivo\n\nsummary(proc_data$m0_edad)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   33.00   46.00   46.09   58.00   88.00",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#análisis-descriptivo",
    "href": "practicos/practico-01.html#análisis-descriptivo",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Análisis descriptivo",
    "text": "Análisis descriptivo\n\nsjmisc::descr(proc_data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n      kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\n\n\nTabla 1: Descriptivos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n1\nconfianza_vecinos\nConfianza en vecinos\n2908\n0.6491288\n3.195667\n1.202232\n4 (1-5)\n\n\n2\nm01\nNivel educacional\n2925\n0.0683293\n5.260513\n2.201502\n9 (1-10)\n\n\n4\nm0_sexo\nSexo del entrevistado\n2927\n0.0000000\n1.602665\n0.489430\n1 (1-2)\n\n\n3\nm0_edad\nEdad del entrevistado\n2927\n0.0000000\n46.090878\n15.286798\n70 (18-88)\n\n\n\n\n\n\n\n\nEn la Tabla 1 podemos observar los descriptivos generales de la base de datos procesada. Notemos la Media de confianza en vecinos = 3.20\nY si queremos visualizar algo más:\n\nproc_data %&gt;% dplyr::select(confianza_vecinos) %&gt;% \n  sjPlot::plot_stackfrq()+\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigura 1: Frecuencias Confianza en vecinos",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#asociación-de-variables",
    "href": "practicos/practico-01.html#asociación-de-variables",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Asociación de variables",
    "text": "Asociación de variables\nPodemos ver la asociación de todas las variables, como lo muestra la ?@cor-complete\n\nM &lt;- cor(proc_data, use = \"complete.obs\") # Usar solo casos con observaciones completas\n\n\ncorrplot.mixed(M)\n\n\n\n\n\n\n\nFigura 2: variables elsoc 2016\n\n\n\n\n\nLa Figura 2 muestra que la asociación de la confianza en vecinos es baja, siendo positiva para educación y edad, y negativa para sexo. La asociación más alta es entre educación y edad, siendo negativa (-0,35).",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#medias-condicionales",
    "href": "practicos/practico-01.html#medias-condicionales",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Medias condicionales",
    "text": "Medias condicionales\nAntes de avanzar desde la correlación al método de regresión es importante conocer el concepto de media condicional.\nImaginemos un juego de tacataca con dos variables: cantidad de juegos previos y puntos obtenidos en un partido. En estas variables, el promedio de puntos es 4. Es decir, si conocemos a algún individuo que pertence al grupo de “datos”, sabemos que su puntaje se encuentra probablemente cercano a 4. ¿Podemos mejorar nuestra estimación utilizando el puntaje de X? Si el sujeto nos dice que ha jugado antes 6 veces, probablemente vamos a estimar un puntaje superior de puntos, tal vez más cercano a 6.\nLo que estamos haciendo es utilizar la información que conocemos de X para dar una estimación de Y, que sea más precisa que el promedio bruto.\n\nMirando el gráfico de nube de puntos, sabemos que tres personas han jugado antes una vez, pero una de ellas tuvo 2 puntos, otra 3 y otra 4. Con estos datos podemos calcular la media de Y para X=1, que sería igual a 3. En otras palabras, la media condicional de Y cuando X=1 es 3. Con esto, uno podría calcular la media condicional para cada punto de X y hacer una estimación más precisa de Y. Sin embargo, este proceso todavía no nos permite generalizar más eficientemte la relación entre X e Y.\n¿Cuántos puntos (Y) se obtienen según la experiencia previa de juego (X)? Esta pregunta nos conduce al cálculo de una recta que atraviese los puntos y que generalice la relación entre X e Y.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#residuos",
    "href": "practicos/practico-01.html#residuos",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Residuos",
    "text": "Residuos\nEn el gráfico anterior vemos que la línea resume la relación entre X e Y, pero claramente es una simplificación que no abarca toda la variabilidad de los datos.\nPor ejemplo, para el sujeto cuya experiencia es haber jugado 1 vez y luego gana 3 puntos, esta línea predice exáctamente su puntaje basada en su experiencia. Sin embargo, el sujeto que ha jugado 3 veces y saca 6 puntos se encuentra más lejos de la línea y por lo tanto esta línea o “modelo predictivo” no representa tan bien su puntaje. A esto se refieren los residuos, que es la diferencia entre el valor predicho (o \\(\\widehat{Y}\\)) y el observado \\(Y\\), siendo los valores predichos de Y los que pasan por la recta a la altura de cada valor de X. Por lo tanto, la mejor recta será aquella que minimice al máximo los residuos.\n\nEl sentido de la recta que resume de mejor manera la relación entre dos variables es que minimice la suma de todos los residuos. ¿Cómo realizar este procedimiento?\n\nPara realizar la suma de los residuos estos se elevan al cuadrado, lo que se denomina Suma de residuos al cuadrado o \\(SS_{residual}\\). Se eleva al cuadrado ya que como hay residuos positivos y negativos, unos cancelarían a otros y la suma seía 0, tal como sucede en la formula de la varianza.\nDe la infinita cantidad de rectas que se pueden trazar, siempre hay una que tiene un valor menor de \\(SS_{residual}\\). Este procedimiento es el que da nombre al proceso de estimación: mínimos (residuos) cuadrados ordinarios, o OLS (Ordinary Least Squares).\n\n¿Cómo funciona esto con nuestro ejemplo?\n\n#Grafico x1 = ACT\ngraph1 &lt;- ggplot(proc_data, aes(x = m0_edad, y = confianza_vecinos)) +\n  geom_point(size = 1) +  # Puntos\n  geom_smooth(method = \"lm\", se = FALSE) +  # Recta de regresión\n  labs(x = \"Edad\", y = \"Confianza en vecinos\")  # Etiquetas de ejes\n\n# Gráfico 2\ngraph2 &lt;- ggplot(proc_data, aes(x = m01, y = confianza_vecinos)) +\n  geom_point(size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Educación\", y = \"Confianza en vecinos\")\nggarrange(graph1, graph2, nrow = 1) # Unir graficos\n\n\n\n\n\n\n\n\nCon el gráfico anterior podemos notar que, si bien ambas variables tienen una asociación positiva con la confianza en vecinos, el tamaño efecto de esta relación es distinto.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#regresiones",
    "href": "practicos/practico-01.html#regresiones",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Regresiones",
    "text": "Regresiones\nPara facilitar la interpretación de los coeficientes de regresión nos aseguramos que las variables categóricas estén como variables categóricas con as_factor. De esta forma nos aseguramos que la estimación de los modelos sea correcta ya que no se puede interpretar sexo como si fuera una variable numérica.\n\nproc_data$sexo &lt;- as_factor(proc_data$m0_sexo)\n\nproc_data &lt;- na.omit(proc_data)\n\nreg1 &lt;- lm(confianza_vecinos ~ 1, data=proc_data)\n\ntab_model(reg1,\n          show.ci = FALSE)\n\n\n\n\n \nconfianza vecinos\n\n\nPredictors\nEstimates\np\n\n\n(Intercept)\n3.20\n&lt;0.001\n\n\nObservations\n2906\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n\n\n\n\n\n\n\n¿Qué valor toma una regresión lineal cuando no incluímos predictores en nuestro modelo?\nEn este caso, lo que nos interesa observar es el intercepto. Un intercepto de 3.20 nos indica la media de la confianza en vecinos.\n\nRegresión lineal simple\nUna regresión lineal simple es aquel modelo que incluye solo un predictor. En este caso construiremos tres modelos distintos con tres variables independientes, es decir, reg2 que incluye como predictor ‘edad’, reg3 incluye educación y reg4 incluye sexo.\nreg2 &lt;- lm(confianza_vecinos ~ m0_edad, data=proc_data)\nreg3 &lt;- lm(confianza_vecinos ~ m01, data=proc_data)\nreg4 &lt;- lm(confianza_vecinos ~ sexo, data=proc_data)\n\ntab_model(reg2, reg3, reg4,\n          show.ci = FALSE,\n          pred.labels = c(\"Intercepto\",\n                          \"Edad\",\n                          \"Educación\",\n                          \"Sexo\"))\n\n\n\n \nconfianza vecinos\nconfianza vecinos\nconfianza vecinos\n\n\nPredictors\nEstimates\np\nEstimates\np\nEstimates\np\n\n\nIntercepto\n2.83\n&lt;0.001\n2.94\n&lt;0.001\n3.27\n&lt;0.001\n\n\nEdad\n0.01\n&lt;0.001\n\n\n\n\n\n\nEducación\n\n\n0.05\n&lt;0.001\n\n\n\n\nSexo\n\n\n\n\n-0.12\n0.010\n\n\nObservations\n2906\n2906\n2906\n\n\nR2 / R2 adjusted\n0.010 / 0.010\n0.008 / 0.008\n0.002 / 0.002\n\n\n\n\n\nLa interpretación de una tabla de regresión debe seguir el orden de presentación de los modelos y el orden de los coeficientes de regresión. En este ejemplo se dará el paso a paso de cómo interpretar las tablas:\nEn el Modelo 1 se incluye edad como predictor, que tiene un coeficiente de regresión de 0,01. Esto indica que por cada unidad que aumenta edad, la confianza en vecinos aumenta en promedio 0,01 unidades. El intercepto es de 2,83, lo que indica que (teóricamente) una persona con edad 0 tendría un promedio de confianza en vecinos de 2,83. Finalmente, el modelo 1 logra explicar el 1% de la varianza de la variable dependiente (R2=0,01).\nEl Modelo 2 incluye la educación de los/as encuestados como variable independiente. Este Modelo indica que por cada unidad que aumenta la educación, la confianza en vecinos aumenta en promedio 0,5 unidades. Si observamos el intercepto, este nos indica que el promedio de confianza en vecinos para las personas sin educación es de 2.94.\nEl modelo 3 indica que las mujeres tendrían -0,12 unidades en la confianza en vecinos en comparación con los hombres. ¿Cómo sabemos que este el efecto de las mujeres? ¿Por qué no al revés? ¿Por qué “en comparación” con los hombres?",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#selección-de-variables",
    "href": "practicos/practico-01.html#selección-de-variables",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Selección de variables",
    "text": "Selección de variables\n\nCargar paquetes, cargar base de datos ELSOC y filtrar por la ola 4 (2019).\nSeleccionar las siguientes variables:\n\nSatisfacción con la democracia: c01\nSociodemográficas: m01 (educación), m0_sexo (sexo), m0_edad (edad).\n\nDefinir cuál es la variable dependiente y cuáles las independientes",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#operacionalización-de-variables",
    "href": "practicos/practico-01.html#operacionalización-de-variables",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Operacionalización de variables",
    "text": "Operacionalización de variables\n\nRecodificar valores perdidos (-999, -888, -777, -666) como NA.\nCambiar etiquetas para que sean más descriptivas.",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#análisis-1",
    "href": "practicos/practico-01.html#análisis-1",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Análisis",
    "text": "Análisis\n\nGráfico descriptivo para satisfacción con la democracia\nEstimar, visualizar e interpretar una matriz de correlaciones con las 4 variables principales.\nEstimar tres modelos de regresión lineal simple\n\nModelo 1: satisfaccion_democracia ~ sexo\nModelo 2: satisfaccion_democracia ~ educacion\nModelo 3: satisfaccion_democracia ~ edad",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "practicos/practico-01.html#reporte",
    "href": "practicos/practico-01.html#reporte",
    "title": "Práctico 01. Regresión lineal I",
    "section": "Reporte",
    "text": "Reporte\n\nPresentar una tabla con los tres modelos.\nIncluir un párrafo breve (máx. 200 palabras) interpretando los coeficientes y \\(R^2\\).",
    "crumbs": [
      "Practicos",
      "Práctico 1 - Regresión lineal simple"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Daniela Olivares\n   Departamento de Sociología N° 328\n   &lt;a href=“mailto:danielaolivarescollio@gmail.com”&gt;danielaolivarescollio@gmail.com\n   Kevin Carrasco\n   Departamento de Sociología N° 328\n   &lt;a href=“mailto:kevin.carrasco@ug.uchile.cl”&gt;kevin.carrasco@ug.uchile.cl\n   KevinCarrascoQ1\n\n\n\n\n\n   Lunes, martes y miércoles\n   Marzo 21–Julio 06, 2025\n   12:00-13:30 AM\n   Sala 334. Depto de Sociología\n   Slack\n\n\n\n\n\nEste curso busca dar un primer acercamiento a la investigación social cuantitativa, abarcando desde aspectos iniciales básicos de estadística descriptiva y visualización de datos, hasta análisis e interpretación de modelos explicativos de investigación social. Asimismo, se busca que los y las estudiantes logren familiarizarse con el uso de Rstudio para el análisis de datos sociales.\nLa metodología incluye clases lectivas y trabajo práctico en R.\n\n\n\nAl finalizar el curso, el/la estudiante podrá elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R.\n\n\n\nAl concluir el curso lo/as estudiantes deberán haber alcanzado los siguientes resultados de aprendizaje:\n\nConocer las etapas de un diseño de investigación social cuantitativa y sus principales elementos\nFormular diseños de investigación social cuantitativa\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos\nInterpretar y analizar los elementos centrales de una base de datos con información social\nAplicar e interpretar técnicas de estadística descriptiva según las distintas características de los datos\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para variables con distinta unidad de medida\nAplicar e interpretar técnicas de regresión lineal y logística para variables numéricas y variables categóricas\n\n\n\n\n\n\n1.1 Elementos básicos de la investigación social\n\nEtapas de la investigación Social\nTipos de diseños\nDiseño de instrumentos de medición\nBases de datos: datos de corte transversal, series de tiempo, cohortes, panel o longitudinal\n\n1.2 Operacionalización y análisis de datos\n\nOperacionalización y niveles de medición\nTidy data: unir, dividir, filtrar y ordenar datos en R\nRecodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\nAgrupación de datos y construcción de variables a partir de datos existentes\nConstrucción de índices y validez de escalas\n\n1.3 Visualización de datos en R\n\nTablas descriptivas y tablas de contingencia\nggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\n\n\n2.1 Inferencia estadística\n2.2 Pruebas de hipótesis\n2.3 Correlación\n\n\n\n3.1 Regresión lineal de mínimos cuadrados\n\nAspectos centrales y supuestos de la regresión MCO\nInterpretación de coeficientes (variables cuantitativas y cualitativas) y efectos de interacción\nRepresentación gráfica de coeficientes de regresión lineal\n\n3.2 Regresión logística binaria\n\nAspectos básicos de la regresión logística\nTipos de coeficientes e interpretación\nRepresentación gráfica (cálculo de probabilidades predichas)\n\n\n\n\n\nWickham, Hadley & Grolemund, Garrett (2017). R for Data Science. Visualize, model, transform, tidy and import data. / Versión en español disponible acá\nMoore, D. S., & Comas, J. (2010). Estadística aplicada básica. Barcelona: Antoni Bosch.\nWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning.\nCamarero, et al (2017) Regresión Logística: Fundamentos y aplicación a la investigación sociológica.\nHair, Joseph F., et al. (2004). Análisis multivariante. 5ta ed. Madrid: Prentice Hall.\nCharte, Francisco (2014). Análisis exploratorio y Visualización de datos con R.\n\n\n\nEl curso se organiza en sesiones semanales, con una parte lectiva seguida de una práctica. En la parte lectiva se transmiten y discuten los conceptos centrales de la investigación cuantitativa. En la parte práctica se aplicarán los conceptos transmitidos en la parte lectiva, además de resolver dudas en el avance de los trabajos de investigación\n\n\n\nLa evaluación consistirá en\n\n\n\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7).\n\n\n\n\n\nEstadística, investigación cuantitativa, manipulación de datos, visualización de datos, interpretación de coeficientes"
  },
  {
    "objectID": "syllabus.html#resumen",
    "href": "syllabus.html#resumen",
    "title": "Programa",
    "section": "",
    "text": "Este curso busca dar un primer acercamiento a la investigación social cuantitativa, abarcando desde aspectos iniciales básicos de estadística descriptiva y visualización de datos, hasta análisis e interpretación de modelos explicativos de investigación social. Asimismo, se busca que los y las estudiantes logren familiarizarse con el uso de Rstudio para el análisis de datos sociales.\nLa metodología incluye clases lectivas y trabajo práctico en R."
  },
  {
    "objectID": "syllabus.html#objetivo-general",
    "href": "syllabus.html#objetivo-general",
    "title": "Programa",
    "section": "",
    "text": "Al finalizar el curso, el/la estudiante podrá elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R."
  },
  {
    "objectID": "syllabus.html#objetivos-específicos",
    "href": "syllabus.html#objetivos-específicos",
    "title": "Programa",
    "section": "",
    "text": "Al concluir el curso lo/as estudiantes deberán haber alcanzado los siguientes resultados de aprendizaje:\n\nConocer las etapas de un diseño de investigación social cuantitativa y sus principales elementos\nFormular diseños de investigación social cuantitativa\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos\nInterpretar y analizar los elementos centrales de una base de datos con información social\nAplicar e interpretar técnicas de estadística descriptiva según las distintas características de los datos\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para variables con distinta unidad de medida\nAplicar e interpretar técnicas de regresión lineal y logística para variables numéricas y variables categóricas"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "",
    "text": "1.1 Elementos básicos de la investigación social\n\nEtapas de la investigación Social\nTipos de diseños\nDiseño de instrumentos de medición\nBases de datos: datos de corte transversal, series de tiempo, cohortes, panel o longitudinal\n\n1.2 Operacionalización y análisis de datos\n\nOperacionalización y niveles de medición\nTidy data: unir, dividir, filtrar y ordenar datos en R\nRecodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\nAgrupación de datos y construcción de variables a partir de datos existentes\nConstrucción de índices y validez de escalas\n\n1.3 Visualización de datos en R\n\nTablas descriptivas y tablas de contingencia\nggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\n\n\n2.1 Inferencia estadística\n2.2 Pruebas de hipótesis\n2.3 Correlación\n\n\n\n3.1 Regresión lineal de mínimos cuadrados\n\nAspectos centrales y supuestos de la regresión MCO\nInterpretación de coeficientes (variables cuantitativas y cualitativas) y efectos de interacción\nRepresentación gráfica de coeficientes de regresión lineal\n\n3.2 Regresión logística binaria\n\nAspectos básicos de la regresión logística\nTipos de coeficientes e interpretación\nRepresentación gráfica (cálculo de probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#bibliografía",
    "href": "syllabus.html#bibliografía",
    "title": "Programa",
    "section": "",
    "text": "Wickham, Hadley & Grolemund, Garrett (2017). R for Data Science. Visualize, model, transform, tidy and import data. / Versión en español disponible acá\nMoore, D. S., & Comas, J. (2010). Estadística aplicada básica. Barcelona: Antoni Bosch.\nWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning.\nCamarero, et al (2017) Regresión Logística: Fundamentos y aplicación a la investigación sociológica.\nHair, Joseph F., et al. (2004). Análisis multivariante. 5ta ed. Madrid: Prentice Hall.\nCharte, Francisco (2014). Análisis exploratorio y Visualización de datos con R."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "",
    "text": "El curso se organiza en sesiones semanales, con una parte lectiva seguida de una práctica. En la parte lectiva se transmiten y discuten los conceptos centrales de la investigación cuantitativa. En la parte práctica se aplicarán los conceptos transmitidos en la parte lectiva, además de resolver dudas en el avance de los trabajos de investigación"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "",
    "text": "La evaluación consistirá en"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "",
    "text": "Nota mínima de aprobación: 4,0 (en escala de 1 a 7)."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "",
    "text": "Estadística, investigación cuantitativa, manipulación de datos, visualización de datos, interpretación de coeficientes"
  },
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "La presente evaluación tiene por objetivo que las y los estudiantes apliquen de forma integral los contenidos del curso a una temática de interés específica utilizando la base de datos del Estudio Social Longitudinal de Chile (ELSOC), en formato de reporte de investigación breve. Se espera un ejercicio de investigación que logre dar cuenta del aprendizaje de las herramientas de análisis estadístico que configuran las habilidades básicas para desarrollar procesos de investigación social, analizando fuentes de información de carácter cuantitativo desde una perspectiva sociológica.\nEn este informe, los estudiantes deberán elaborar un reporte de investigación que desarrolle de forma integrada los aspectos de diseño de la investigación, análisis estadístico y presentación de resultados, así como la elaboración de conclusiones.\nCuestiones a considerar:\n\nEl trabajo debe ser realizado en parejas\nSe realizarán dos entregas tipo reporte de investigación, que se irá construyendo a lo largo del semestre.\nSe recomienda que elaboren un problema de investigación que trate sobre las características sociales de algún problema actual de la sociedad chilena, y que sea factible de investigar con los datos del Estudio Social Longitudinal de Chile (ELSOC).\nLa investigación a desarrollar debe ser de tipo descriptiva, esto quiere decir que se trata de una pregunta de investigación que se refiere a la forma, magnitud o características que tienen unas determinadas variables en una población."
  },
  {
    "objectID": "trabajos.html#evaluación",
    "href": "trabajos.html#evaluación",
    "title": "Trabajos",
    "section": "",
    "text": "La presente evaluación tiene por objetivo que las y los estudiantes apliquen de forma integral los contenidos del curso a una temática de interés específica utilizando la base de datos del Estudio Social Longitudinal de Chile (ELSOC), en formato de reporte de investigación breve. Se espera un ejercicio de investigación que logre dar cuenta del aprendizaje de las herramientas de análisis estadístico que configuran las habilidades básicas para desarrollar procesos de investigación social, analizando fuentes de información de carácter cuantitativo desde una perspectiva sociológica.\nEn este informe, los estudiantes deberán elaborar un reporte de investigación que desarrolle de forma integrada los aspectos de diseño de la investigación, análisis estadístico y presentación de resultados, así como la elaboración de conclusiones.\nCuestiones a considerar:\n\nEl trabajo debe ser realizado en parejas\nSe realizarán dos entregas tipo reporte de investigación, que se irá construyendo a lo largo del semestre.\nSe recomienda que elaboren un problema de investigación que trate sobre las características sociales de algún problema actual de la sociedad chilena, y que sea factible de investigar con los datos del Estudio Social Longitudinal de Chile (ELSOC).\nLa investigación a desarrollar debe ser de tipo descriptiva, esto quiere decir que se trata de una pregunta de investigación que se refiere a la forma, magnitud o características que tienen unas determinadas variables en una población."
  },
  {
    "objectID": "trabajos.html#instrucciones-entrega-inicial",
    "href": "trabajos.html#instrucciones-entrega-inicial",
    "title": "Trabajos",
    "section": "Instrucciones entrega inicial",
    "text": "Instrucciones entrega inicial\nPara la entrega del informe se espera que, habiendo seleccionado un fenómeno específico de interés, se desarrollen los siguientes puntos:\n\n\n\n\n\n\n\n\nCOMPONENTES\nDETALLE\nPUNTAJE\n\n\nFormulación del problema\nFundamente el interés sociológico que habilita el estudio de la temática elegida (¿Qué se va a estudiar?, ¿Por qué es importante?, ¿Qué se sabe sobre el tema?), utilizando al menos 3 referencias bibliográficas. Además, formule una pregunta y un objetivo general de investigación. Estos deben ser coherentes entre sí y con la formulación del problema expuesta en el apartado anterior. El objetivo de investigación formulado debe permitir entender cómo se analizará la temática elegida. Además, la pregunta debe ser de carácter descriptiva. (1 plana)\n2,0\n\n\n\n\nDefinición base de datos\nDefina la fuente de información a utilizar indicando el nombre de la base de datos y la institución que la disponibiliza, la población que busca representar el estudio, el procedimiento de muestreo utilizado y el tamaño de la muestra. Dado que trabajaremos solo con el Estudio Social Longitudinal de Chile (ELSOC) 2022, se espera que los grupos describan qué busca medir y representar el módulo de la encuesta elegido. (½ plana)\n2,0\n\n\n\n\nDefinición variables a utilizar\nSeleccionar un mínimo de 6 variables para, mediante su estudio, responder a la pregunta de investigación. Todas las variables deben remitir al tema de interés: 2 de las variables deben ser de nivel de medición de intervalo o razón, 1 variable debe ser de nivel de medición ordinal y 1 variable debe ser de nivel de medición nominal, además, un conjunto de variables para armar una escala o índice.\nPara cada variable debe indicar: i) una breve descripción que especifique el nivel de medición de la  variable, su nombre en la base de datos y el fraseo en la encuesta, ii) explique qué aspecto del fenómeno de interés representa y iii) su utilidad para resolver la pregunta de investigación. La selección de variables debe ser coherente con la formulación del problema y la pregunta y objetivos de investigación propuestos. (1 plana)\n2,0\n\n\nTablas de frecuencia\nCalcular una tabla de frecuencia (absoluta y relativa) para las variables nominales y ordinales e interpretar. La interpretación de tablas debe buscar aportar con elementos que permitan construir una respuesta a la pregunta y objetivos de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de tendencia central\nCalcular e interpretar las medidas de tendencia central para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,5\n\n\nGráficos\nPresentar al menos 2 gráficos seleccionando para su construcción aquellas variables más relevantes para el problema de investigación. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los gráficos deben ser realizados en R.\n2,5\n\n\nConclusiones\nEn las conclusiones se deben sintetizar los aspectos más relevantes de los análisis estadísticos ya expuestos, articulando toda la información trabajada debe presentarse una respuesta tentativa a la pregunta de investigación. Este resumen de los resultados, así como las conclusiones, deben dialogar con lo planteado en la introducción de su trabajo, haciendo referencia a las fuentes bibliográficas utilizadas en la presentación del problema de investigación. Además, debe reflexionar sobre los límites de su diseño de investigación y señalar posibles ejes de investigación que podrían ser considerados en futuras indagaciones. Se valorará la pertinencia sociológica de la conclusión (1 plana).\n2,0\n\n\nTrabajo en R\nAdemás del informe, entregar la carpeta con el Proyecto R, que contenga un archivo .Rproject, y las carpetas input, procesamiento y output.\n\nLa carpeta input debe contener la base de datos, manual de usuario, libro de códigos.\nLa carpeta procesamiento debe contener un archivo de sintaxis para el procesamiento y otro para el análisis de los datos.\nLa carpeta output debe contener la base de datos procesada y el resto de salidas asociadas (tablas, gráficos, etc.).\n\nSe evaluará que los códigos utilizados generen las salidas (tablas, gráficos, etc.) que se presentan en el informe.\n3,0"
  },
  {
    "objectID": "trabajos.html#instrucciones-segunda-entrega",
    "href": "trabajos.html#instrucciones-segunda-entrega",
    "title": "Trabajos",
    "section": "Instrucciones segunda entrega",
    "text": "Instrucciones segunda entrega\n\n\n\n\n\n\n\n\nCOMPONENTES\nDETALLE\nPUNTAJE\n\n\nFormulación del problema\nFundamente el interés sociológico que habilita el estudio de la temática elegida (¿Qué se va a estudiar?, ¿Por qué es importante?, ¿Qué se sabe sobre el tema?), utilizando al menos 3 referencias bibliográficas. Además, formule una pregunta y un objetivo general de investigación. Estos deben ser coherentes entre sí y con la formulación del problema expuesta en el apartado anterior. El objetivo de investigación formulado debe permitir entender cómo se analizará la temática elegida. Además, la pregunta debe ser de carácter descriptiva. (1 plana)\n1,0\n\n\n\n\nDefinición base de datos\nDefina la fuente de información a utilizar indicando el nombre de la base de datos y la institución que la disponibiliza, la población que busca representar el estudio, el procedimiento de muestreo utilizado y el tamaño de la muestra. Dado que trabajaremos solo con el Estudio Social Longitudinal de Chile (ELSOC) 2022, se espera que los grupos describan qué busca medir y representar el módulo de la encuesta elegido. (½ plana)\n0,5\n\n\n\n\nDefinición variables a utilizar\nSeleccionar un mínimo de 4 variables para, mediante su estudio, responder a la pregunta de investigación. Todas las variables deben remitir al tema de interés: 2 de las variables deben ser de nivel de medición de intervalo o razón, 1 variable debe ser de nivel de medición ordinal y 1 variable debe ser de nivel de medición nominal, además, un conjunto de variables para armar una escala o índice.\nPara cada variable debe indicar: i) una breve descripción que especifique el nivel de medición de la  variable, su nombre en la base de datos y el fraseo en la encuesta, ii) explique qué aspecto del fenómeno de interés representa y iii) su utilidad para resolver la pregunta de investigación. La selección de variables debe ser coherente con la formulación del problema y la pregunta y objetivos de investigación propuestos. (1 plana)\n2,0\n\n\nTablas de frecuencia\nCalcular una tabla de frecuencia (absoluta y relativa) para las variables nominales y ordinales e interpretar. La interpretación de tablas debe buscar aportar con elementos que permitan construir una respuesta a la pregunta y objetivos de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de tendencia central\nCalcular e interpretar las medidas de tendencia central (estadístico muestral) para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de dispersión\nCalcular el rango, la desviación estándar y el coeficiente de variación (estadístico muestral) para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de posición\nCalcular el valor mínimo y máximo, el cuartil 1 y el cuartil 3 (estadístico muestral) para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nGráficos\nPresentar al menos 2 gráficos seleccionando para su construcción aquellas variables más relevantes para el problema de investigación. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los gráficos deben ser realizados en R.\n2,0\n\n\nÍndices y escalas\nConstruir al menos un índice o escala a partir del conjunto de variables seleccionado. Este índice o escala debe reportar e interpretar el nivel de consistencia interna de las variables\n2,0\n\n\nEstimación puntual, intervalo de confianza y error\nCalcular los parámetros e intervalos de confianza para dos de las variables seleccionadas. Además, debe elaborar una tabla resumen que sintetice todos los indicadores que considere relevantes para interpretar la información. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nConclusiones\nEn las conclusiones se deben sintetizar los aspectos más relevantes de los análisis estadísticos ya expuestos, articulando toda la información trabajada debe presentarse una respuesta tentativa a la pregunta de investigación. Este resumen de los resultados, así como las conclusiones, deben dialogar con lo planteado en la introducción de su trabajo, haciendo referencia a las fuentes bibliográficas utilizadas en la presentación del problema de investigación. Además, debe reflexionar sobre los límites de su diseño de investigación y señalar posibles ejes de investigación que podrían ser considerados en futuras indagaciones. Se valorará la pertinencia sociológica de la conclusión (1 plana).\n2,0\n\n\nTrabajo en R\nAdemás del informe, entregar la carpeta con el Proyecto R, que contenga un archivo .Rproject, y las carpetas input, procesamiento y output.\n\nLa carpeta input debe contener la base de datos, manual de usuario, libro de códigos.\nLa carpeta procesamiento debe contener un archivo de sintaxis para el procesamiento y otro para el análisis de los datos.\nLa carpeta output debe contener la base de datos procesada y el resto de salidas asociadas (tablas, gráficos, etc.).\n\nSe evaluará que los códigos utilizados generen las salidas (tablas, gráficos, etc.) que se presentan en el informe.\n3,0"
  },
  {
    "objectID": "trabajos.html#fecha-y-formato-de-entrega",
    "href": "trabajos.html#fecha-y-formato-de-entrega",
    "title": "Trabajos",
    "section": "Fecha y formato de entrega",
    "text": "Fecha y formato de entrega\nEl formato de entrega del informe debe ser un documento en formato PDF (.pdf), que debe estar alojado en la carpeta output del Proyecto R. Fecha de entrega: viernes 13 de junio hasta las 23:59 vía módulo Tareas en plataforma U-Cursos. \n\nEntregas atrasadas hasta las 23:59 del sábado 14 de junio tendrán 0,5 puntos de descuento  sobre la nota final. \nEntregas atrasadas hasta el domingo 15 de junio hasta las 23:59 tendrán 1,0 punto de descuento sobre la nota final. No serán evaluadas entregas posteriores a esta fecha."
  },
  {
    "objectID": "trabajos.html#sobre-plagio",
    "href": "trabajos.html#sobre-plagio",
    "title": "Trabajos",
    "section": "Sobre plagio",
    "text": "Sobre plagio\nTodos los trabajos se procesan en software para detección de plagio: evidencia de una situación de plagio implica obtención de la nota mínima en la evaluación (1,0) junto con constituirse como causal de reprobación de la asignatura."
  },
  {
    "objectID": "trabajos.html#recomendaciones-para-la-entrega",
    "href": "trabajos.html#recomendaciones-para-la-entrega",
    "title": "Trabajos",
    "section": "Recomendaciones para la entrega",
    "text": "Recomendaciones para la entrega\n\nMáxima de escritura: una idea por párrafo. Si comienza una idea nueva, se recomienda comenzar otro párrafo. Al revés, si el párrafo siguiente habla de lo mismo, sumarlo al párrafo anterior. \nLa idea del párrafo se resume en la primera parte del párrafo, lo que en inglés se llama “topic sentence”. \nDeclarar domicilio disciplinar: ej, mencionar la palabra “sociología” en el primer/segundo párrafo, esto fuerza que la investigación se enmarque en la disciplina.\n\nEn caso de tener dudas, no dude en contactar a sus ayudantes respectivos, o bien, vía foro U-Cursos al equipo docente de la asignatura."
  },
  {
    "objectID": "practicos/index.html",
    "href": "practicos/index.html",
    "title": "Prácticos",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.3.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto (o en blanco):\n\n\n\n\n\n\n\n\nNota\n\n\n\nAlternativa a lo anterior: https://posit.cloud/\n\nVersión online de Rstudio\nUtilizar en caso de problemas con PC",
    "crumbs": [
      "Practicos",
      "Descripción"
    ]
  },
  {
    "objectID": "practicos/index.html#r-y-rstudio",
    "href": "practicos/index.html#r-y-rstudio",
    "title": "Prácticos",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.3.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto (o en blanco):\n\n\n\n\n\n\n\n\nNota\n\n\n\nAlternativa a lo anterior: https://posit.cloud/\n\nVersión online de Rstudio\nUtilizar en caso de problemas con PC",
    "crumbs": [
      "Practicos",
      "Descripción"
    ]
  },
  {
    "objectID": "content/11-content.html#lecturas",
    "href": "content/11-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nPráctica en R"
  },
  {
    "objectID": "content/09-content.html#lecturas",
    "href": "content/09-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/05-content.html#lecturas",
    "href": "content/05-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nMoore: Residuos",
    "crumbs": [
      "Clases",
      "Sesiones",
      "03: Sesión 3"
    ]
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "01: Sesión 1"
    ]
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in thsi course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nMoore 7: Inferencia para medias (482-543)",
    "crumbs": [
      "Clases",
      "Sesiones",
      "04: Sesión 4"
    ]
  },
  {
    "objectID": "content/06-content.html#lecturas",
    "href": "content/06-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/08-content.html#lecturas",
    "href": "content/08-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/10-content.html#lecturas",
    "href": "content/10-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Presentaciones, lecturas y actividades",
    "section": "",
    "text": "En esta sección se encuentran los documentos de presentación correspondientes a cada clase, lecturas y también actividades prácticas.",
    "crumbs": [
      "Clases",
      "Información general",
      "Presentaciones, lecturas y actividades"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases teóricas y las actividades prácticas. Las clases se realizarán los días Viernes 09:00 a 10:50 en sala 329\n\nClases ( ): Lecturas, documentos de presentación y video (en caso que la sesión sea grabada)\nPrácticas y evaluaciones (): Actividades prácticas a desarrollar durante la semana.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Prácticas y evaluaciones\n Lecturas y material adicional\n\n\n\n\n Marzo \n\n\n\n\n\nViernes 17\n00. Presentación e 01. introducción\n1. Aproximación inicial a R\n- Leer detalladamente programa del curso\n\n\n\n\nUNIDAD 1: Estadística descriptiva\n\n\n\nViernes 24\n2.Operacionalización de variables \n2.Operacionalización de variables\n- Wickham & Grolemund, (2017). cap. 1 Introducción \n\n\nViernes 31\n3. Visualización de datos\n-\n- Wickham & Grolemund, (2017). cap. 2 Explorar\n\n\n Abril \n\n\n\n\n\nViernes 07\nViernes santo\n\n\n\n\nViernes 14\n1° semana presencial\n\n\n\n\nViernes 21\n\nEvaluación\n\n\n\n\n\n\nUNIDAD 2: Estadística Correlacional\n\n\n\nViernes 28\n4. Introducción a la inferencia estadística\n\n\n\n\n Mayo \n\n\n\n\n\nViernes 05\n1° semana de pausa reflexiva\n\n\n\n\nViernes 12\n5. Correlación\n\n\n\n\nViernes 19\n6. Índices y análisis factorial\n\n\n\n\nViernes 26\n2° semana presencial\n\n\n\n\n\n\n\nUNIDAD 3: Regresión lineal y regresión logística\n\n\n\n Junio \n\n\n\n\n\nViernes 02\n7. Regresión lineal de mínimos cuadrados\n\n\n\n\nViernes 09\n2° semana de pausa reflexiva\n\n\n\n\nViernes 16\n**8. Regresión logística binaria: interpretación de coeficientes y cálculo de probabilidades\n\n\n\n\nViernes 23\n10. Análisis factorial y regresión lineal en R\n\n\n\n\nViernes 30\n11. Supuestos de regresión y valores predichos\n\n\n\n\n Julio \n\n\n\n\n\nViernes 07\n3° semana presencial\n\n\n\n\nViernes 14\n\nEvaluación"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Métodos estadísticos para ciencias sociales III\n        ",
    "section": "",
    "text": "Métodos estadísticos para ciencias sociales III\n        \n        \n            Universidad Andrés Bello\n        \n        \n            • Segundo semestre 2025Departamento de Sociología FACSOUniversidad Andrés Bello\n        \n    \n    \n        \n    \n\n\n\n\n\n\nProfesor\n\n   Kevin Carrasco\n   Departamento de Sociología N° 328\n   kevin.carrasco@ug.uchile.cl\n   KevinCarrascoQ1\n\n\n\nInformación del curso\n\n   Lunes, martes y miércoles\n   Marzo 21–Julio 06, 2025\n   12:00-13:30 AM\n   Sala 334. Depto de Sociología\n\n\n\nContacto\nA través de correo"
  },
  {
    "objectID": "practicos/practico-03.html",
    "href": "practicos/practico-03.html",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "",
    "text": "Una de las ideas fundamentales de la inferencia es determinar si nuestros análisis estadísticos pueden ser extrapolados a la población que estamos estudiando. En el contexto de regresión, esto se traduce en la significación estadística del coeficiente \\(\\beta\\), lo que es distinto del tamaño del efecto del \\(\\beta\\). Por ejemplo, podemos tener un \\(\\beta\\) de tamaño 3, pero eso no nos dice nada todavía sobre si es estadísticamente significativo.\nEntonces, la pregunta central de inferencia en regresión es: ¿Es nuestro coeficiente \\(\\beta\\) estadísticamente significativo?\nLa significación estadística se refiere a poder afirmar si el \\(\\beta\\) es distinto de cero en la población. Esta afirmación se puede realizar con un cierto nivel de probabilidad de error p, donde el concepto central es el error estándar.\n\n\nEl error estándar (SE, por su sigla en inglés) es un concepto central en inferencia ya que nos permite aseverar con un grado de probabilidad de error si nuestro coeficiente existe en la población (o en otras palabras, que nuestro coeficiente es distinto de cero en la población).\nEl ejemplo más simple para dar cuenta del error estándar es relativo al promedio: podemos calcular el promedio de la muestra, pero no sabemos con certeza si este promedio corresponde al de la población. Podríamos hacer una estimación más apropiada si extrajéramos varias muestras de datos, obtuviéramos el promedio de cada una y calcularamos una desviación estándar de estos promedios. Esta es justamente la idea detrás del cálculo del error estándar: entregar un posible rango de variación del promedio en la población (sumando y restando errores estándar al promedio). Y para ello, hacemos referencia a la distribución normal, que nos dice que aproximadamente el 68% de los valores se encuentran a +/- 1 SE y un 95% de los valores a +/- 2 SE.\nPero claramente es muy costoso extraer varias muestras y en general trabajamos con una; por ello, se utiliza una fórmula de SE para una muestra basada en el teorema central del límite, que nos dice (para el caso del promedio) que \\(SE_{\\bar{x}}\\frac{s}{\\sqrt{N}}\\) donde \\(s\\) es la desviación estándar y \\(N\\) es el tamaño de la muestra.\nAhora, como N está en el denominador, en la medida que aumente el N de la muestra, el error estándar será más pequeño. Esto es relevante saberlo, ya que un promedio o también un \\(\\beta\\) puede ser o no estadísticamente significativo según el tamaño muestral, y por lo tanto el tamaño del coeficiente no está relacionado directamente con su significación estadística.\nEjemplo\nSupongamos que nuestra muestra de 3703 casos en realidad corresponde a la Población, de modo tal que vamos a extraer 14 muestras aleatorias de distinto tamaño a modo de ilustrar cambios en la estimación en la medida que aumenta el tamaño muestral.\n\nlibrary(dplyr)\nload(url(\"https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess.RData\")) # Cargar base de datos\nset.seed(123)\nelsoc_n30  &lt;- sample_n(tbl = elsoc_18,size = 30 )  %&gt;% mutate(dataset=30 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n50  &lt;- sample_n(tbl = elsoc_18,size = 50 )  %&gt;% mutate(dataset=50 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n75  &lt;- sample_n(tbl = elsoc_18,size = 75 )  %&gt;% mutate(dataset=75 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n100 &lt;- sample_n(tbl = elsoc_18,size = 100)  %&gt;% mutate(dataset=100,mean_ess=mean(ess,na.rm = T))\nelsoc_n200 &lt;- sample_n(tbl = elsoc_18,size = 200)  %&gt;% mutate(dataset=200,mean_ess=mean(ess,na.rm = T))\nelsoc_n300 &lt;- sample_n(tbl = elsoc_18,size = 300)  %&gt;% mutate(dataset=300 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n400 &lt;- sample_n(tbl = elsoc_18,size = 400)  %&gt;% mutate(dataset=400,mean_ess=mean(ess,na.rm = T))\nelsoc_n700 &lt;- sample_n(tbl = elsoc_18,size = 700)  %&gt;% mutate(dataset=700,mean_ess=mean(ess,na.rm = T))\nelsoc_n800 &lt;- sample_n(tbl = elsoc_18,size = 800)  %&gt;% mutate(dataset=800,mean_ess=mean(ess,na.rm = T))\nelsoc_n900 &lt;- sample_n(tbl = elsoc_18,size = 900)  %&gt;% mutate(dataset=900,mean_ess=mean(ess,na.rm = T))\nelsoc_n1000&lt;- sample_n(tbl = elsoc_18,size = 1000) %&gt;% mutate(dataset=1000,mean_ess=mean(ess,na.rm = T))\nelsoc_n1500&lt;- sample_n(tbl = elsoc_18,size = 1500) %&gt;% mutate(dataset=1500,mean_ess=mean(ess,na.rm = T))\nelsoc_n2000&lt;- sample_n(tbl = elsoc_18,size = 2000) %&gt;% mutate(dataset=2000,mean_ess=mean(ess,na.rm = T))\nelsoc_n2500&lt;- sample_n(tbl = elsoc_18,size = 2500) %&gt;% mutate(dataset=2500,mean_ess=mean(ess,na.rm = T))\n# elsoc      &lt;- elsoc_18 %&gt;% mutate(dataset=3703,mean_ess=mean(ess,na.rm = T))\n\nfullmat&lt;- bind_rows(elsoc_n30 ,elsoc_n50 ,elsoc_n75 ,elsoc_n100,elsoc_n200,elsoc_n300,elsoc_n400,elsoc_n700,elsoc_n800,elsoc_n900,elsoc_n1000,elsoc_n1500,elsoc_n2000,elsoc_n2500)\nfullmat &lt;- fullmat %&gt;% mutate(mean_ssta=mean(elsoc_18$ess,na.rm = T))\n\nLuego de obtener las muestras, calculamos la media, desviación estándar y error estándar para cada una de ellas:\n\ntab_full&lt;- fullmat %&gt;% group_by(dataset) %&gt;% summarise(mean=mean(ess,na.rm = T), sd=sd(ess,na.rm = T),SE=sd/sqrt(n()))\ntab_full\n\n# A tibble: 14 × 4\n   dataset  mean    sd     SE\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1      30  4.07  1.41 0.258 \n 2      50  4.58  1.59 0.225 \n 3      75  4.39  1.60 0.185 \n 4     100  4.4   1.49 0.149 \n 5     200  4.46  1.47 0.104 \n 6     300  4.3   1.55 0.0893\n 7     400  4.36  1.58 0.0789\n 8     700  4.35  1.62 0.0611\n 9     800  4.38  1.54 0.0544\n10     900  4.36  1.58 0.0525\n11    1000  4.40  1.57 0.0498\n12    1500  4.39  1.56 0.0403\n13    2000  4.42  1.56 0.0349\n14    2500  4.38  1.58 0.0317\n\n\nEs posible observar que tanto la media como la desviación estándar van cambiando en la medida que aumenta el tamaño de la muestra, pero si observamos el error estándar, este va sistemáticamente disminuyendo en la medida que aumenta el tamaño muestral.\nPara ilustrar cómo va cambiando la dispersión y la media “muestral” (rojo) con respecto a la “poblacional” (verde), se puede observar el siguiente gráfico:\n\nPor lo tanto, el valor del error estándar depende del tamaño de la muestra, y por lo tanto el tamaño de la muestra va a afectar la significación estadística de los coeficientes de regresión.\n\n\n\nEn regresión nos interesa saber si las diferencias en Y con respecto a los distintos niveles o valores de X son significativas, es decir estadísticamente distintas de 0 con un cierto nivel de probabilidad.\nPara poder calcular la probabilidad de error nos basamos en una distribución teórica, que es la distribución normal en su versión ajustada al tamaño muestral: la distribución T. Esta distribución nos permite obtener un valor de contraste o valor crítico para un cierto nivel de probabilidad de error (por ejemplo, p=0.05), con el cual contrastamos el T obtenido en nuestra estimación.\nPor lo tanto, para esto se requiere:\n\ncalcular el T de cada \\(\\beta\\) de regresión\nestablecer un nivel de probabilidad de error (ej: p=0.05, para un 95% de confianza)\ncalcular el valor crítico\ncontrastar: si T &gt; valor crítico T, entonces se puede establecer que el coeficiente es estadísticamente significativo con una probabilidad de error p&lt;0.05. O alternativamente, se rechaza la hipótesis nula (que nos dice que \\(\\beta=0\\)) con un 95% de confianza.\n\nTodos estos pasos son realizados automáticamente mediante software de estimación (como R), pero vamos a hacerlo paso a paso en un ejemplo mínimo (=pocos datos) con los datos de la práctica 3 de regresión simple:\n\ndatos &lt;- read.csv(\"https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\", sep=\"\")\n\n\nTenemos entonces tres columnas:\n\nid: número único que identifica a cada sujeto\njuegos_x: número de veces que ha jugado previamente\npuntos_y: numero de puntos que obtuvo en el juego actual\n\nEstimamos el modelo de regresión y vemos los resultados:\n\nreg1 &lt;-lm(puntos_y ~ juegos_x, data = datos)\nstargazer::stargazer(reg1, type = \"text\")\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                             puntos_y          \n-----------------------------------------------\njuegos_x                     0.500***          \n                              (0.132)          \n                                               \nConstant                     2.500***          \n                              (0.458)          \n                                               \n-----------------------------------------------\nObservations                    23             \nR2                             0.405           \nAdjusted R2                    0.376           \nResidual Std. Error       1.091 (df = 21)      \nF Statistic           14.280*** (df = 1; 21)   \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nEl \\(\\beta\\) (calculado paso a paso en la Práctica 3) nos dice que por cada punto que aumenta la experiencia en juegos (X), el puntaje obtenido (Y) aumenta 0.5 puntos. Atendamos ahora a la información adicional de la tabla relacionada con inferencia:\n\nun número entre paréntesis bajo el \\(\\beta\\), corresponde al error estándar\ntres asteriscos al lado del \\(\\beta\\), que refieren al pie de la tabla donde el número de asteriscos (entre 1 y 3) se asocia a distintos niveles de probabilidad de error.\n\nEl error estándar del \\(\\beta\\) o \\(SE_{\\beta}\\) es lo que nos permite calcular T, ya que \\(T=\\beta / SE_{\\beta}\\). Existen diferentes alternativas para el cálculo de \\(SE_{\\beta}\\), para el caso de este ejemplo con un predictor X continuo vamos a utilizar:\n\\[SE_{\\beta}=\\sqrt{\\frac{ \\frac{1}{N-2}-\\sum(\\hat{y}-y)²}{\\sum(x-\\bar{x})²}}\\]\nDonde en el numerador se encuentra la sumatoria de los residuos al cuadrado multiplicado por 1/N-2, y en el denominador es la suma de cuadrados de X. Para demostrar paso a paso la obtención de estos términos vamos a agregar una serie de columnas a nuestra base de datos:\n\n#Variable de valores predichos\ndatos$estimado&lt;- (2.5 + datos$juegos_x*0.5)\n\n# Estimamos el residuo\ndatos$residuo &lt;- datos$puntos_y - datos$estimado\n\n# Estimamos los residuos al cuadrado\ndatos$residuo2 &lt;- datos$residuo^2\n\n# Y finalmente las diferencias de X del promedio\ndatos$xprom_x &lt;- datos$juegos_x - mean(datos$juegos_x)\n\n# ... al cuadrado\ndatos$xprom_x2 &lt;- (datos$xprom_x)^2\n\ndatos\n\n   id juegos_x puntos_y estimado residuo residuo2 xprom_x xprom_x2\n1   1        0        2      2.5    -0.5     0.25      -3        9\n2   2        0        3      2.5     0.5     0.25      -3        9\n3   3        1        2      3.0    -1.0     1.00      -2        4\n4   4        1        3      3.0     0.0     0.00      -2        4\n5   5        1        4      3.0     1.0     1.00      -2        4\n6   6        2        2      3.5    -1.5     2.25      -1        1\n7   7        2        3      3.5    -0.5     0.25      -1        1\n8   8        2        4      3.5     0.5     0.25      -1        1\n9   9        2        5      3.5     1.5     2.25      -1        1\n10 10        3        2      4.0    -2.0     4.00       0        0\n11 11        3        3      4.0    -1.0     1.00       0        0\n12 12        3        4      4.0     0.0     0.00       0        0\n13 13        3        5      4.0     1.0     1.00       0        0\n14 14        3        6      4.0     2.0     4.00       0        0\n15 15        4        3      4.5    -1.5     2.25       1        1\n16 16        4        4      4.5    -0.5     0.25       1        1\n17 17        4        5      4.5     0.5     0.25       1        1\n18 18        4        6      4.5     1.5     2.25       1        1\n19 19        5        4      5.0    -1.0     1.00       2        4\n20 20        5        5      5.0     0.0     0.00       2        4\n21 21        5        6      5.0     1.0     1.00       2        4\n22 22        6        5      5.5    -0.5     0.25       3        9\n23 23        6        6      5.5     0.5     0.25       3        9\n\n\nAhora obtenemos la suma de los residuos al cuadrado (residuo2) y la suma de las diferencias de promedio de X al cuadrado:\n\nsum(datos$residuo2)\n\n[1] 25\n\nsum(datos$xprom_x2)\n\n[1] 68\n\n\nReemplazamos en la fórmula:\n\\(SE_{\\beta}=\\sqrt{\\frac{ \\frac{1}{N-2}*\\sum(\\hat{y}-y)²}{\\sum(x-\\bar{x})²}}=\\sqrt{\\frac{ \\frac{1}{23-2}*25}{68}}\\)\nY realizamos el cálculo:\n\nsqrt(((1/21)*25)/68 )\n\n[1] 0.132314\n\n\nQue es equivalente al valor entre paréntesis bajo el \\(\\beta\\) en la tabla de regresión de arriba, y que corresponde al error estándar.\nCon el error estándar, ahora calculamos T:\n\\(T=\\frac{\\beta}{SE_{\\beta}}=\\frac{0.5}{0.132}=3.787\\)\nY ahora contrastamos este valor con el valor crítico de T, basado en la distribución T y que se obtiene de la tabla de valores correspondiente o de un software estadístico como R. Para esto necesitamos establecer el nivel deseado de probabilidad de error, convencionalmente p=0.05, y los grados de libertad (gl) que se calculan como N-k-1, donde k equivale al número de predictores (en este caso 1). Por lo tanto gl=23-1-1=21.\nY un tema adicional sobre el valor p: vamos a establecer un valor que considere tanto situaciones de coeficiente positivo como negativo (prueba de dos colas), que es la manera convencional para rechazar hipótesis nulas en el caso de regresión. Por lo tanto, para la búsqueda del valor crítico dividimos el p a la mitad (0.05/2), quedando entonces en 0.025.\nCon p=0.025 y gl=21 obtenemos el valor crítico:\n\nqt(0.975, 21)\n\n[1] 2.079614\n\n\nNuestro valor T de 3.387 es mayor que el valor crítico de 2.07, por lo tanto podemos decir que nuestro beta es estadísticamente significativo con un 95% de confianza. Veamos ahora si podemos hacer esta afirmación con un mayor nivel de confianza: 99%. Para eso, calculamos la T de dos colas para un p=0.01/2=0.005, por lo tanto el valor crítico se calcula a partir de 0.995\n\nqt(0.995, 21)\n\n[1] 2.83136\n\n\nEn este caso, el T del \\(\\beta\\) de nuestro modelo también es superior a este valor crítico (3.387&gt;2.831), por lo que podemos decir que nuestro beta es estadísticamente significativo con un 99% de confianza. Alternativamente, que rechazamos la hipótesis nula (que dice que \\(\\beta=0\\) en la población) con una probabilidad de error p&lt;0.01. Esto se representa en la tabla de regresión con asteriscos al lado del \\(\\beta\\), lo cual puede variar según la función que produzca la tabla. En la tabla de arriba generada con stargazer un nivel de probabilidad de error p&lt;0.01 se representa con 3 asteriscos, pero otras funciones como la que veremos más adelante sjPlot::tab_model los dos asteriscos equivalen a p&lt;0.01 y tres a p&lt;0.001:\n\n\nOtro concepto asociado con inferencia es el intervalo de confianza, que se obtiene sumando y restando errores estándar al \\(\\beta\\) de regresión. Con esto no solo se obtiene un rango probable de variación del \\(\\beta\\), sino que también es posible establecer falta de significancia estadística cuando el intervalo pasa por el valor 0. De esta manera, es una manera relacionada y complementaria de hacer análisis de inferencia además de la prueba T.\nPara obtener el intervalo de confianza se suma/resta al \\(\\beta\\) el error estándar por el valor crítico de T para el nivel de confianza correspondiente. En nuestro ejemplo, para un 95% de confianza el T crítico es 2.079, por lo tanto considerando el \\(\\beta\\) de 0.5 y el error de 0.132:\n\n0.5 - (2.079 * 0.132)\n\n[1] 0.225572\n\n0.5 + (2.079 * 0.132)\n\n[1] 0.774428\n\n\nPor lo tanto, podemos decir con un 95% de confianza que \\(\\beta\\) varía entre 0.225 y 0.774, y que es estadísticamente significativo ya que el intervalo no pasa por cero, que es lo mismo que decir que es estadísticamente distinto de 0.\nToda esta información la podemos obtener en R con tablas como la siguiente:\n\nsjPlot::tab_model(reg1,\n        show.se=TRUE,\n        digits=3,\n        p.style = \"star\")\n\n\n\n\n \npuntos y\n\n\nPredictors\nEstimates\nstd. Error\nCI\n\n\n(Intercept)\n2.500 ***\n0.458\n1.549 – 3.451\n\n\njuegos x\n0.500 **\n0.132\n0.225 – 0.775\n\n\nObservations\n23\n\n\nR2 / R2 adjusted\n0.405 / 0.376\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nA continuación más detalles de generación de tablas e interpretación",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#error-estándar-se-y-tamaño-muestral",
    "href": "practicos/practico-03.html#error-estándar-se-y-tamaño-muestral",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "",
    "text": "El error estándar (SE, por su sigla en inglés) es un concepto central en inferencia ya que nos permite aseverar con un grado de probabilidad de error si nuestro coeficiente existe en la población (o en otras palabras, que nuestro coeficiente es distinto de cero en la población).\nEl ejemplo más simple para dar cuenta del error estándar es relativo al promedio: podemos calcular el promedio de la muestra, pero no sabemos con certeza si este promedio corresponde al de la población. Podríamos hacer una estimación más apropiada si extrajéramos varias muestras de datos, obtuviéramos el promedio de cada una y calcularamos una desviación estándar de estos promedios. Esta es justamente la idea detrás del cálculo del error estándar: entregar un posible rango de variación del promedio en la población (sumando y restando errores estándar al promedio). Y para ello, hacemos referencia a la distribución normal, que nos dice que aproximadamente el 68% de los valores se encuentran a +/- 1 SE y un 95% de los valores a +/- 2 SE.\nPero claramente es muy costoso extraer varias muestras y en general trabajamos con una; por ello, se utiliza una fórmula de SE para una muestra basada en el teorema central del límite, que nos dice (para el caso del promedio) que \\(SE_{\\bar{x}}\\frac{s}{\\sqrt{N}}\\) donde \\(s\\) es la desviación estándar y \\(N\\) es el tamaño de la muestra.\nAhora, como N está en el denominador, en la medida que aumente el N de la muestra, el error estándar será más pequeño. Esto es relevante saberlo, ya que un promedio o también un \\(\\beta\\) puede ser o no estadísticamente significativo según el tamaño muestral, y por lo tanto el tamaño del coeficiente no está relacionado directamente con su significación estadística.\nEjemplo\nSupongamos que nuestra muestra de 3703 casos en realidad corresponde a la Población, de modo tal que vamos a extraer 14 muestras aleatorias de distinto tamaño a modo de ilustrar cambios en la estimación en la medida que aumenta el tamaño muestral.\n\nlibrary(dplyr)\nload(url(\"https://multivariada.netlify.app/assignment/data/proc/ELSOC_ess.RData\")) # Cargar base de datos\nset.seed(123)\nelsoc_n30  &lt;- sample_n(tbl = elsoc_18,size = 30 )  %&gt;% mutate(dataset=30 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n50  &lt;- sample_n(tbl = elsoc_18,size = 50 )  %&gt;% mutate(dataset=50 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n75  &lt;- sample_n(tbl = elsoc_18,size = 75 )  %&gt;% mutate(dataset=75 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n100 &lt;- sample_n(tbl = elsoc_18,size = 100)  %&gt;% mutate(dataset=100,mean_ess=mean(ess,na.rm = T))\nelsoc_n200 &lt;- sample_n(tbl = elsoc_18,size = 200)  %&gt;% mutate(dataset=200,mean_ess=mean(ess,na.rm = T))\nelsoc_n300 &lt;- sample_n(tbl = elsoc_18,size = 300)  %&gt;% mutate(dataset=300 ,mean_ess=mean(ess,na.rm = T))\nelsoc_n400 &lt;- sample_n(tbl = elsoc_18,size = 400)  %&gt;% mutate(dataset=400,mean_ess=mean(ess,na.rm = T))\nelsoc_n700 &lt;- sample_n(tbl = elsoc_18,size = 700)  %&gt;% mutate(dataset=700,mean_ess=mean(ess,na.rm = T))\nelsoc_n800 &lt;- sample_n(tbl = elsoc_18,size = 800)  %&gt;% mutate(dataset=800,mean_ess=mean(ess,na.rm = T))\nelsoc_n900 &lt;- sample_n(tbl = elsoc_18,size = 900)  %&gt;% mutate(dataset=900,mean_ess=mean(ess,na.rm = T))\nelsoc_n1000&lt;- sample_n(tbl = elsoc_18,size = 1000) %&gt;% mutate(dataset=1000,mean_ess=mean(ess,na.rm = T))\nelsoc_n1500&lt;- sample_n(tbl = elsoc_18,size = 1500) %&gt;% mutate(dataset=1500,mean_ess=mean(ess,na.rm = T))\nelsoc_n2000&lt;- sample_n(tbl = elsoc_18,size = 2000) %&gt;% mutate(dataset=2000,mean_ess=mean(ess,na.rm = T))\nelsoc_n2500&lt;- sample_n(tbl = elsoc_18,size = 2500) %&gt;% mutate(dataset=2500,mean_ess=mean(ess,na.rm = T))\n# elsoc      &lt;- elsoc_18 %&gt;% mutate(dataset=3703,mean_ess=mean(ess,na.rm = T))\n\nfullmat&lt;- bind_rows(elsoc_n30 ,elsoc_n50 ,elsoc_n75 ,elsoc_n100,elsoc_n200,elsoc_n300,elsoc_n400,elsoc_n700,elsoc_n800,elsoc_n900,elsoc_n1000,elsoc_n1500,elsoc_n2000,elsoc_n2500)\nfullmat &lt;- fullmat %&gt;% mutate(mean_ssta=mean(elsoc_18$ess,na.rm = T))\n\nLuego de obtener las muestras, calculamos la media, desviación estándar y error estándar para cada una de ellas:\n\ntab_full&lt;- fullmat %&gt;% group_by(dataset) %&gt;% summarise(mean=mean(ess,na.rm = T), sd=sd(ess,na.rm = T),SE=sd/sqrt(n()))\ntab_full\n\n# A tibble: 14 × 4\n   dataset  mean    sd     SE\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1      30  4.07  1.41 0.258 \n 2      50  4.58  1.59 0.225 \n 3      75  4.39  1.60 0.185 \n 4     100  4.4   1.49 0.149 \n 5     200  4.46  1.47 0.104 \n 6     300  4.3   1.55 0.0893\n 7     400  4.36  1.58 0.0789\n 8     700  4.35  1.62 0.0611\n 9     800  4.38  1.54 0.0544\n10     900  4.36  1.58 0.0525\n11    1000  4.40  1.57 0.0498\n12    1500  4.39  1.56 0.0403\n13    2000  4.42  1.56 0.0349\n14    2500  4.38  1.58 0.0317\n\n\nEs posible observar que tanto la media como la desviación estándar van cambiando en la medida que aumenta el tamaño de la muestra, pero si observamos el error estándar, este va sistemáticamente disminuyendo en la medida que aumenta el tamaño muestral.\nPara ilustrar cómo va cambiando la dispersión y la media “muestral” (rojo) con respecto a la “poblacional” (verde), se puede observar el siguiente gráfico:\n\nPor lo tanto, el valor del error estándar depende del tamaño de la muestra, y por lo tanto el tamaño de la muestra va a afectar la significación estadística de los coeficientes de regresión.",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#inferencia-en-regresión",
    "href": "practicos/practico-03.html#inferencia-en-regresión",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "",
    "text": "En regresión nos interesa saber si las diferencias en Y con respecto a los distintos niveles o valores de X son significativas, es decir estadísticamente distintas de 0 con un cierto nivel de probabilidad.\nPara poder calcular la probabilidad de error nos basamos en una distribución teórica, que es la distribución normal en su versión ajustada al tamaño muestral: la distribución T. Esta distribución nos permite obtener un valor de contraste o valor crítico para un cierto nivel de probabilidad de error (por ejemplo, p=0.05), con el cual contrastamos el T obtenido en nuestra estimación.\nPor lo tanto, para esto se requiere:\n\ncalcular el T de cada \\(\\beta\\) de regresión\nestablecer un nivel de probabilidad de error (ej: p=0.05, para un 95% de confianza)\ncalcular el valor crítico\ncontrastar: si T &gt; valor crítico T, entonces se puede establecer que el coeficiente es estadísticamente significativo con una probabilidad de error p&lt;0.05. O alternativamente, se rechaza la hipótesis nula (que nos dice que \\(\\beta=0\\)) con un 95% de confianza.\n\nTodos estos pasos son realizados automáticamente mediante software de estimación (como R), pero vamos a hacerlo paso a paso en un ejemplo mínimo (=pocos datos) con los datos de la práctica 3 de regresión simple:\n\ndatos &lt;- read.csv(\"https://multivariada.netlify.app/slides/03-regsimple1/tacataca.txt\", sep=\"\")\n\n\nTenemos entonces tres columnas:\n\nid: número único que identifica a cada sujeto\njuegos_x: número de veces que ha jugado previamente\npuntos_y: numero de puntos que obtuvo en el juego actual\n\nEstimamos el modelo de regresión y vemos los resultados:\n\nreg1 &lt;-lm(puntos_y ~ juegos_x, data = datos)\nstargazer::stargazer(reg1, type = \"text\")\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                             puntos_y          \n-----------------------------------------------\njuegos_x                     0.500***          \n                              (0.132)          \n                                               \nConstant                     2.500***          \n                              (0.458)          \n                                               \n-----------------------------------------------\nObservations                    23             \nR2                             0.405           \nAdjusted R2                    0.376           \nResidual Std. Error       1.091 (df = 21)      \nF Statistic           14.280*** (df = 1; 21)   \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nEl \\(\\beta\\) (calculado paso a paso en la Práctica 3) nos dice que por cada punto que aumenta la experiencia en juegos (X), el puntaje obtenido (Y) aumenta 0.5 puntos. Atendamos ahora a la información adicional de la tabla relacionada con inferencia:\n\nun número entre paréntesis bajo el \\(\\beta\\), corresponde al error estándar\ntres asteriscos al lado del \\(\\beta\\), que refieren al pie de la tabla donde el número de asteriscos (entre 1 y 3) se asocia a distintos niveles de probabilidad de error.\n\nEl error estándar del \\(\\beta\\) o \\(SE_{\\beta}\\) es lo que nos permite calcular T, ya que \\(T=\\beta / SE_{\\beta}\\). Existen diferentes alternativas para el cálculo de \\(SE_{\\beta}\\), para el caso de este ejemplo con un predictor X continuo vamos a utilizar:\n\\[SE_{\\beta}=\\sqrt{\\frac{ \\frac{1}{N-2}-\\sum(\\hat{y}-y)²}{\\sum(x-\\bar{x})²}}\\]\nDonde en el numerador se encuentra la sumatoria de los residuos al cuadrado multiplicado por 1/N-2, y en el denominador es la suma de cuadrados de X. Para demostrar paso a paso la obtención de estos términos vamos a agregar una serie de columnas a nuestra base de datos:\n\n#Variable de valores predichos\ndatos$estimado&lt;- (2.5 + datos$juegos_x*0.5)\n\n# Estimamos el residuo\ndatos$residuo &lt;- datos$puntos_y - datos$estimado\n\n# Estimamos los residuos al cuadrado\ndatos$residuo2 &lt;- datos$residuo^2\n\n# Y finalmente las diferencias de X del promedio\ndatos$xprom_x &lt;- datos$juegos_x - mean(datos$juegos_x)\n\n# ... al cuadrado\ndatos$xprom_x2 &lt;- (datos$xprom_x)^2\n\ndatos\n\n   id juegos_x puntos_y estimado residuo residuo2 xprom_x xprom_x2\n1   1        0        2      2.5    -0.5     0.25      -3        9\n2   2        0        3      2.5     0.5     0.25      -3        9\n3   3        1        2      3.0    -1.0     1.00      -2        4\n4   4        1        3      3.0     0.0     0.00      -2        4\n5   5        1        4      3.0     1.0     1.00      -2        4\n6   6        2        2      3.5    -1.5     2.25      -1        1\n7   7        2        3      3.5    -0.5     0.25      -1        1\n8   8        2        4      3.5     0.5     0.25      -1        1\n9   9        2        5      3.5     1.5     2.25      -1        1\n10 10        3        2      4.0    -2.0     4.00       0        0\n11 11        3        3      4.0    -1.0     1.00       0        0\n12 12        3        4      4.0     0.0     0.00       0        0\n13 13        3        5      4.0     1.0     1.00       0        0\n14 14        3        6      4.0     2.0     4.00       0        0\n15 15        4        3      4.5    -1.5     2.25       1        1\n16 16        4        4      4.5    -0.5     0.25       1        1\n17 17        4        5      4.5     0.5     0.25       1        1\n18 18        4        6      4.5     1.5     2.25       1        1\n19 19        5        4      5.0    -1.0     1.00       2        4\n20 20        5        5      5.0     0.0     0.00       2        4\n21 21        5        6      5.0     1.0     1.00       2        4\n22 22        6        5      5.5    -0.5     0.25       3        9\n23 23        6        6      5.5     0.5     0.25       3        9\n\n\nAhora obtenemos la suma de los residuos al cuadrado (residuo2) y la suma de las diferencias de promedio de X al cuadrado:\n\nsum(datos$residuo2)\n\n[1] 25\n\nsum(datos$xprom_x2)\n\n[1] 68\n\n\nReemplazamos en la fórmula:\n\\(SE_{\\beta}=\\sqrt{\\frac{ \\frac{1}{N-2}*\\sum(\\hat{y}-y)²}{\\sum(x-\\bar{x})²}}=\\sqrt{\\frac{ \\frac{1}{23-2}*25}{68}}\\)\nY realizamos el cálculo:\n\nsqrt(((1/21)*25)/68 )\n\n[1] 0.132314\n\n\nQue es equivalente al valor entre paréntesis bajo el \\(\\beta\\) en la tabla de regresión de arriba, y que corresponde al error estándar.\nCon el error estándar, ahora calculamos T:\n\\(T=\\frac{\\beta}{SE_{\\beta}}=\\frac{0.5}{0.132}=3.787\\)\nY ahora contrastamos este valor con el valor crítico de T, basado en la distribución T y que se obtiene de la tabla de valores correspondiente o de un software estadístico como R. Para esto necesitamos establecer el nivel deseado de probabilidad de error, convencionalmente p=0.05, y los grados de libertad (gl) que se calculan como N-k-1, donde k equivale al número de predictores (en este caso 1). Por lo tanto gl=23-1-1=21.\nY un tema adicional sobre el valor p: vamos a establecer un valor que considere tanto situaciones de coeficiente positivo como negativo (prueba de dos colas), que es la manera convencional para rechazar hipótesis nulas en el caso de regresión. Por lo tanto, para la búsqueda del valor crítico dividimos el p a la mitad (0.05/2), quedando entonces en 0.025.\nCon p=0.025 y gl=21 obtenemos el valor crítico:\n\nqt(0.975, 21)\n\n[1] 2.079614\n\n\nNuestro valor T de 3.387 es mayor que el valor crítico de 2.07, por lo tanto podemos decir que nuestro beta es estadísticamente significativo con un 95% de confianza. Veamos ahora si podemos hacer esta afirmación con un mayor nivel de confianza: 99%. Para eso, calculamos la T de dos colas para un p=0.01/2=0.005, por lo tanto el valor crítico se calcula a partir de 0.995\n\nqt(0.995, 21)\n\n[1] 2.83136\n\n\nEn este caso, el T del \\(\\beta\\) de nuestro modelo también es superior a este valor crítico (3.387&gt;2.831), por lo que podemos decir que nuestro beta es estadísticamente significativo con un 99% de confianza. Alternativamente, que rechazamos la hipótesis nula (que dice que \\(\\beta=0\\) en la población) con una probabilidad de error p&lt;0.01. Esto se representa en la tabla de regresión con asteriscos al lado del \\(\\beta\\), lo cual puede variar según la función que produzca la tabla. En la tabla de arriba generada con stargazer un nivel de probabilidad de error p&lt;0.01 se representa con 3 asteriscos, pero otras funciones como la que veremos más adelante sjPlot::tab_model los dos asteriscos equivalen a p&lt;0.01 y tres a p&lt;0.001:\n\n\nOtro concepto asociado con inferencia es el intervalo de confianza, que se obtiene sumando y restando errores estándar al \\(\\beta\\) de regresión. Con esto no solo se obtiene un rango probable de variación del \\(\\beta\\), sino que también es posible establecer falta de significancia estadística cuando el intervalo pasa por el valor 0. De esta manera, es una manera relacionada y complementaria de hacer análisis de inferencia además de la prueba T.\nPara obtener el intervalo de confianza se suma/resta al \\(\\beta\\) el error estándar por el valor crítico de T para el nivel de confianza correspondiente. En nuestro ejemplo, para un 95% de confianza el T crítico es 2.079, por lo tanto considerando el \\(\\beta\\) de 0.5 y el error de 0.132:\n\n0.5 - (2.079 * 0.132)\n\n[1] 0.225572\n\n0.5 + (2.079 * 0.132)\n\n[1] 0.774428\n\n\nPor lo tanto, podemos decir con un 95% de confianza que \\(\\beta\\) varía entre 0.225 y 0.774, y que es estadísticamente significativo ya que el intervalo no pasa por cero, que es lo mismo que decir que es estadísticamente distinto de 0.\nToda esta información la podemos obtener en R con tablas como la siguiente:\n\nsjPlot::tab_model(reg1,\n        show.se=TRUE,\n        digits=3,\n        p.style = \"star\")\n\n\n\n\n \npuntos y\n\n\nPredictors\nEstimates\nstd. Error\nCI\n\n\n(Intercept)\n2.500 ***\n0.458\n1.549 – 3.451\n\n\njuegos x\n0.500 **\n0.132\n0.225 – 0.775\n\n\nObservations\n23\n\n\nR2 / R2 adjusted\n0.405 / 0.376\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nA continuación más detalles de generación de tablas e interpretación",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#librerías",
    "href": "practicos/practico-03.html#librerías",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Librerías",
    "text": "Librerías\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instalar pacman\npacman::p_load(dplyr,readxl, summarytools, stargazer, webshot, equatiomatic)",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#datos",
    "href": "practicos/practico-03.html#datos",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Datos",
    "text": "Datos\nLos datos a utilizar corresponden a resultados de pruebas de conocimiento en distintas areas de 200 estudiantes de educación secundaria.\n\ndata &lt;- read.csv(\"https://multivariada.netlify.app/assignment/data/hsb2.csv\")\n\n\nDirectorio de trabajo :Directorio de trabajo \nPara el trabajo de análisis de datos se recomienda establecer claramente el directorio de trabajo, es decir, la carpeta que contiene los archivos de datos, los códigos y los resultados. Esta carpeta es el lugar donde uno se posiciona para hacer los análisis, llamar otros archivos y exportar archivos. De otra manera, todos los archivos necesarios para el análisis se encuentran en esta carpeta, lo que se conoce como carpeta autocontenida.\nPara esto, varias opciones:\n\nen RStudio, Session &gt; Set Working Directory &gt; Choose Directory\ntambién vía consola con el comando setwd(ruta-hacia-la-carpeta-local)\no también se puede trabajar en un directorio contenido o cerrado con la función de Rprojects\n\nSi se quiere verificar en qué carpeta se está trabajando, comando getwd()\nCon esto entonces, si los datos están guardados en la misma carpeta, entonces se llaman simplemente data &lt;-read.csv(\"hsb2.csv\"). No se requiere dar la ruta completa justamente porque el programa ya sabe dónde uno está posicionado. Asimismo, al momento de guardar/exportar algún resultado, automáticamente quedará en la carpeta de trabajo.\nSi los datos (o otro archivo que se quiera llamar) no se encuentran en el directorio raíz sino en una subcarpeta, entonces se le indica la ruta de la siguiente manera; ejemplo con datos guardados en subdirectorio “datos”: data &lt;-read.csv(\"datos/hsb2.csv\")",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#ajustes-y-descriptivos",
    "href": "practicos/practico-03.html#ajustes-y-descriptivos",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Ajustes y descriptivos",
    "text": "Ajustes y descriptivos\nPrimero seleccionamos las variables que vamos a usar en el ejemplo y cambiamos las etiquetas de las variables a español.\n\nnames(data)\n\n [1] \"id\"      \"female\"  \"race\"    \"ses\"     \"schtyp\"  \"prog\"    \"read\"   \n [8] \"write\"   \"math\"    \"science\" \"socst\"  \n\ndata &lt;- data %&gt;% select (science,math,female, socst, read)\ndata &lt;- data %&gt;% rename(ciencia=science, matematicas =math, mujer=female, status=socst, lectura=read)\n\n\nview(dfSummary(data, headings=FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nciencia [integer]\n\n\n\nMean (sd) : 51.9 (9.9)\n\n\nmin ≤ med ≤ max:\n\n\n26 ≤ 53 ≤ 74\n\n\nIQR (CV) : 14 (0.2)\n\n\n\n34 distinct values\n\n200 (100.0%)\n0 (0.0%)\n\n\n2\nmatematicas [integer]\n\n\n\nMean (sd) : 52.6 (9.4)\n\n\nmin ≤ med ≤ max:\n\n\n33 ≤ 52 ≤ 75\n\n\nIQR (CV) : 14 (0.2)\n\n\n\n40 distinct values\n\n200 (100.0%)\n0 (0.0%)\n\n\n3\nmujer [integer]\n\n\n\nMin : 0\n\n\nMean : 0.5\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n91\n(\n45.5%\n)\n\n\n1\n:\n109\n(\n54.5%\n)\n\n\n\n\n200 (100.0%)\n0 (0.0%)\n\n\n4\nstatus [integer]\n\n\n\nMean (sd) : 52.4 (10.7)\n\n\nmin ≤ med ≤ max:\n\n\n26 ≤ 52 ≤ 71\n\n\nIQR (CV) : 15 (0.2)\n\n\n\n22 distinct values\n\n200 (100.0%)\n0 (0.0%)\n\n\n5\nlectura [integer]\n\n\n\nMean (sd) : 52.2 (10.3)\n\n\nmin ≤ med ≤ max:\n\n\n28 ≤ 50 ≤ 76\n\n\nIQR (CV) : 16 (0.2)\n\n\n\n30 distinct values\n\n200 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-25\n\n\n\n\nGrabar / exportar tablas :Exportar tablas \nMuchas de las tablas producidas con R son en formato html, es decir, archivos para ser publicados en formato web. Por lo tanto, en caso de querer pegar esa imagen en un documento tipo Word hay que hacer un paso intermedio. Una posibilidad es hacer una captura de pantalla del visor de R, pero también se puede generar una imagen desde R con la librería webshot.\nPara eso, el procedimiento en general es:\n\ngenerar un archivo html de la imagen (output) generado por R\nguardar una imagen de ese archivo\n\nEjemplo, para tablas generadas con summarytools (como la de dfSummary):\nprint(dfSummary(data, headings = FALSE), file = \"tabla_desc.html\") # esto genera un html\nwebshot(\"tabla_desc.html\",\"tabla_desc.png\") # esto genera la imagen\nPara tablas generadas con stargazer\nstargazer(reg1, type=\"html\",  out = \"reg1.html\")\nwebshot(\"reg1.html\",\"reg1.png\")\nY para tablas de regresión con sjPlot:\nsjPlot::tab_model(reg1, show.ci=FALSE, file = \"reg1_tab.html\")\nwebshot(\"reg1_tab.html\",\"reg1_tab.png\")",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#modelos-de-regresión",
    "href": "practicos/practico-03.html#modelos-de-regresión",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Modelos de regresión",
    "text": "Modelos de regresión\n\nLógica de presentación de modelos\nLa forma en que se presentan los modelos en regresión múltiple depende de las hipótesis que se estan contrastando, y de la definición del/a investigador/a sobre cuáles son los predictores principales y cuáles son las variables de control. Pensemos en este caso que nuestra hipótesis principal es que el puntaje de ciencias se puede predecir con los puntajes de matemáticas y lectura, pero queremos controlar estas asociaciones por sexo y estatus. En este caso, podríamos presentar dos modelos, uno solamente con los predictores principales, y luego un segundo modelo con los controles para ver si los efectos se mantienen. También podríamos pensar en tres modelos: uno con matemáticas, otro con ciencias, y otro con ambos y además controles. La decisión de cómo presentar los modelos depende principalmente de las hipótesis que se están contrastando, y también de que los resultados permitan hacer la mejor discusión posible.\n\n\nEstimación\nVamos a estimar un primer modelo con las variables asociadas a la hipótesis principal, y luego un segundo con las variables control:\n\\[\n\\operatorname{ciencia} = \\alpha + \\beta_{1}(\\operatorname{matematicas}) + \\beta_{2}(\\operatorname{lectura}) + \\epsilon\n\\] \\[\n\\operatorname{ciencia} = \\alpha + \\beta_{1}(\\operatorname{matematicas}) + \\beta_{2}(\\operatorname{lectura}) + \\beta_{3}(\\operatorname{mujer}) + \\beta_{4}(\\operatorname{status}) + \\epsilon\n\\]\nPara estimar estos modelos en R:\n\nreg1 &lt;- lm(ciencia ~ matematicas + lectura, data=data)\nreg2 &lt;- lm(ciencia ~ matematicas + lectura + mujer + status, data=data)\n\nPara presentar los resultados de regresión existen diferentes librerías en R, como stargazer, texreg, sjPlot. En este caso vamos a utilizar la función tab_model de sjPlot:\n\nsjPlot::tab_model(list(reg1,reg2))\n\n\n\n\n \nciencia\nciencia\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n11.62\n5.59 – 17.64\n&lt;0.001\n12.33\n6.03 – 18.62\n&lt;0.001\n\n\nmatematicas\n0.40\n0.26 – 0.54\n&lt;0.001\n0.39\n0.24 – 0.54\n&lt;0.001\n\n\nlectura\n0.37\n0.23 – 0.50\n&lt;0.001\n0.34\n0.19 – 0.48\n&lt;0.001\n\n\nmujer\n\n\n\n-2.01\n-4.03 – 0.01\n0.051\n\n\nstatus\n\n\n\n0.05\n-0.07 – 0.17\n0.424\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.478 / 0.473\n0.489 / 0.479\n\n\n\n\n\n\n\nEsta tabla tiene las opciones por defecto. En general, para cada predictor hay dos piezas de información importante: la estimación del coeficiente de regresión \\(\\beta\\) (estimates), y una estimación referida a inferencia/significación estadística (en este caso CI, intervalo de confianza). Esta segunda información es en general el error estándar, pero también puede ser t (que es el coeficiente dividido por el error estándar), o el intervalo de confianza, dado usualmente por el \\(\\beta\\) +/- 1.96 SE para un 95% de confianza (como aparece en esta tabla). Según el output, la información de inferencia puede aparecer abajo del coeficiente, o al lado como en esta tabla.\nAbajo vamos a hacer algunos ajustes en la tabla, presentando el error estándar en lugar del intervalo, y reemplazando la columna del nivel de probabilidad de error (p) por asteriscos que indican el nivel de significación de cada coeficiente, lo cual hace más rápida la interpretación. También cambiamos algunas etiquetas de la tabla para que sea más fácil de leer:\n\nsjPlot::tab_model(list(reg1,reg2),\n        show.se=TRUE,\n        show.ci=FALSE,\n        digits=3,\n        p.style = \"stars\",\n        dv.labels = c(\"Modelo 1\", \"Modelo 2\"),\n        string.pred = \"Predictores\",\n        string.est = \"β\")\n\n\n\n\n \nModelo 1\nModelo 2\n\n\nPredictores\nβ\nstd. Error\nβ\nstd. Error\n\n\n(Intercept)\n11.616 ***\n3.054\n12.325 ***\n3.194\n\n\nmatematicas\n0.402 ***\n0.073\n0.389 ***\n0.074\n\n\nlectura\n0.365 ***\n0.066\n0.335 ***\n0.073\n\n\nmujer\n\n\n-2.010 \n1.023\n\n\nstatus\n\n\n0.050 \n0.062\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.478 / 0.473\n0.489 / 0.479\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nY otra alternativa es la siguiente:\n\nsjPlot::tab_model(list(reg1,reg2),\n                  show.se=TRUE,\n                  show.ci=FALSE,\n                  digits=3,\n                  p.style = \"stars\",\n                  dv.labels = c(\"Modelo 1\", \"Modelo 2\"),\n                  string.pred = \"Predictores\",\n                  string.est = \"β\",\n                  collapse.se = TRUE,\n                  title = \"Modelos de regresión para puntaje en ciencia &lt;br&gt; (Errores estándar entre paréntesis)\")\n\n\nModelos de regresión para puntaje en ciencia\n(Errores estándar entre paréntesis)\n\n\n\n\n\n\n\n \nModelo 1\nModelo 2\n\n\nPredictores\nβ\nβ\n\n\n(Intercept)\n11.616 ***\n(3.054)\n12.325 ***\n(3.194)\n\n\nmatematicas\n0.402 ***\n(0.073)\n0.389 ***\n(0.074)\n\n\nlectura\n0.365 ***\n(0.066)\n0.335 ***\n(0.073)\n\n\nmujer\n\n-2.010 \n(1.023)\n\n\nstatus\n\n0.050 \n(0.062)\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.478 / 0.473\n0.489 / 0.479\n\n\n* p&lt;0.05   ** p&lt;0.01   *** p&lt;0.001\n\n\n\n\n\n\n\nY para presentar en forma de ecuaciones, quedaría de la siguiente manera:\n\\[\n\\operatorname{\\widehat{ciencia}} = 11.62 + 0.4(\\operatorname{matematicas}) + 0.37(\\operatorname{lectura})\n\\] \\[\n\\operatorname{\\widehat{ciencia}} = 12.33 + 0.39(\\operatorname{matematicas}) + 0.34(\\operatorname{lectura}) - 2.01(\\operatorname{mujer}) + 0.05(\\operatorname{status})\n\\]\n\nPara transformar automáticamente las estimaciones de regresión en R a ecuaciones:\nEsto se puede hacer si se utiliza RMarkdown (no es requisito en este curso, para los interesad_s pueden revisar material del curso ciencia social abierta )\n\nInstalar librería equatiomatic. No está en CRAN, así que para instalar:remotes::install_github(\"datalorax/equatiomatic\")\nLa función para extraer la ecuación es extract_eq, por ejemplo: extract_eq(reg1)\nPara que el resultado pueda ser renderizado desde un documento RMarkdown a pdf o html, debe estar en un chunk con las siguientes especificaciones:\n\n```{r results='asis', echo=FALSE}\nextract_eq(reg1)\nextract_eq(reg2)\n```\n\nPara presentar las ecuaciones con los coeficientes ya estimados, extract_eq(reg1, use_coefs = TRUE)\n\n\n\n\nInterpretación\nLos coeficientes nos hablan de la relación entre las variables independientes y la variable dependiente. Nos muestran la magnitud del cambio predicho en el puntaje de ciencia por cada 1 unidad en que aumenta el predictor.\nPara matematica el coeficiente es de 0.402 en el modelo 1 y baja a 0.389 en el modelo 2. Entonces, por cada punto adicional en la prueba de matemáticas en el modelo 2 se presenta un incremento de 0.389 en el puntaje de ciencia, manteniendo todas las demás variables constantes. Respecto a la inferencia, existen distintas maneras de dar cuenta de la significación estadística. Por ejemplo, se puede decir que este valor es estadísticamente significativo con un 99,9% de confianza, o con una probabilidad de error p&lt;0.001.\n\nPara reportar estos resultados de manera más resumida siguiendo las indicaciones de reporte de APA (American Psychological Association): El puntaje en matemáticas predice significativamente el puntaje de ciencias (modelo 1), b = -.40, SE = .07, p &lt; .001, controlando por el puntaje en lectura. Al agregar los controles de sexo y estatus (modelo 2), el puntaje en matemáticas disminuye levemente pero mantiene su nivel de significación, b = -.39, SE = .07, p &lt; .001.\n\nCon respecto a lectura, en el modelo 2 es posible observar un coeficiente de 0.335. Esto implica que por cada unidad que aumenta el puntaje de lectura se predice un incremento de 0.335 puntos en ciencia, manteniendo todas las demás variables contantes. El coeficiente es estadísticamente significativo con una probabilidad de error p&lt;0.001.\nPara la variable mujer podemos observar que el coeficiente tiene un valor de -2.010 en el modelo 2. Al ser mujer una variable dicotómica donde 1 es mujer y 0 es hombre, la estimación nos indica que para las mujeres el puntaje predicho promedio en ciencias es -2.010 puntos más bajo con respecto al promedio de los hombres, manteniendo todas las demás variables constantes. En términos exclusivamente estadísticos, la variable mujer no es significativamente distinta de 0 cuando empleamos un nivel de confianza del 95%, debido a que el valor \\(p\\) es mayor a 0.05.\nSi observamos el coeficiente de status tenemos un valor de 0.050. Entonces, por cada unidad en que incrementa el estatus se predice un incremento de 0.050 puntos en ciencia, manteniendo todas las demás variables constantes. Sin embargo, no es estadísticamente significativo a un 95% de confianza.\nStd Error: Esta columna corresponde a los errores estándar de los coeficientes de regresión (Estimate). Estos errores estándar son empleados para testear en qué medida los coeficientes son distintos de 0 en la población. El procedimiento es dividir el coeficiente por su error estándar para obtener el valor \\(t\\), los que luego se contrastan con la tabla de valores críticos t para obtener la probabilidad de error (que ya aparece automáticamente en la tabla). Además, los errores estándar pueden ser utilizados para calcular los intervalos de confianza.\nUna manera de presentar los resultados de un modelo de regresión es a través de la visualización de los coeficientes de regresión con sus respectivos intervalos de confianza. La ventaja de este tipo de gráficos es que podemos observar la magnitud del coeficiente y las “barras de error” que representan el intervalo de confianza inferior y superior. Utilizando un intervalo de confianza de 95% de confianza:\n\nsjPlot::plot_model(reg2,ci.lvl = c(0.95), title = \"\",vline.color = \"grey\",line.size = 1)\n\n\n\n\nModelo 2\n\n\n\n\nLo que nos muestra este gráfico es el valor del coeficiente en el punto, y en las líneas que salen del punto se extienden según su intervalo de confianza. De acuerdo a las reglas de inferencia en regresión, lo que estamos contrastando es que el valor de este coeficiente es distinto de 0 en la población, con un cierto valor de probabilidad. Por lo tanto, si agregamos un intervalo de confianza (valores probables) asociado a una probabilidad de error, entonces podemos decir que este coeficiente es estadísticamente distinto de 0 en la población. Y en el gráfico, esto sucede cuando los intervalos no tocan el 0.\n\n\nAjuste global del modelo\nR2: El R2 (R-cuadrado) es la proporción de la varianza de la variable dependiente (ciencias) la cual puede ser predicha por las variables independientes (matemáticas, mujer, estatus, lectura). En la Tabla 1 tenemos que para el Modelo (1), este valor nos indica que un 47,7% de la varianza en el puntaje de ciencias se asocia a matemáticas. Luego, en el Modelo (2), el R-cuadrado nos indica que el 48,9% de la varianza de ciencias puede ser predicha conjuntamente por las variables independientes matemáticas, lectura, mujer y status. Como vemos, la incorporación de controles aporta levemente al R2, lo cual se relaciona con que estos predictores no son estadísticamente significativos.\nAdjusted R2: En la medida que se incorporan predictores al modelo, cada uno va contribuyendo a explicar la varianza de la variable dependiente. Así, se podría continuar agregando predictores al modelo, incrementando la capacidad explicativa pero también de cierto modo debido a la variabilidad adicional en una muestra particular con la que estemos trabajando. Por esta razón, el R-cuadrado ajustado busca demostrar un valor estimado más realista del R-cuadrado para la población bajo análisis, penalizando por la inclusión de predictores adicionales. En el caso del Modelo (2) de la Tabla 1, el valor del R-cuadrado es de 0.489, mientras que el R-cuadrado ajustado es de 0.479, el cual es calculado a través de la fórmula \\(1 – ((1 – R^2)((N – 1) /( N – k – 1))\\).\nEntonces, si el número de observaciones (\\(N\\)) es pequeño y el número de predictores (\\(k\\))es grande, tendremos una mayor discrepancia entre el R-cuadrado y el R-cuadrado ajustado. Por otro lado, cuando el número de observaciones es grande en contraste con el número de predictores tendremos que el valor del R-cuadrado y el R-cuadrado ajustado serán mucho más similares debido.\nPor lo tanto, al momento de realizar la intepretación corresponde basarse en los coeficientes del R2 ajustado.",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#cargar-datos",
    "href": "practicos/practico-03.html#cargar-datos",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Cargar datos",
    "text": "Cargar datos\nUtiliza la base de datos hsb2 disponible:\n\ndata &lt;- read.csv(\"https://multivariada.netlify.app/assignment/data/hsb2.csv\")\n\nSelecciona las siguientes variables:\n\nread (puntaje de lectura, dependiente)\nmath (puntaje de matemáticas)\nsocst (puntaje de ciencias sociales)\nfemale (0 = hombre, 1 = mujer)",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#descriptivos",
    "href": "practicos/practico-03.html#descriptivos",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Descriptivos",
    "text": "Descriptivos\n\nCalcula el promedio y desviación estándar de cada variable seleccionada.\nReflexiona: ¿qué nos dice el tamaño de la desviación estándar sobre la dispersión de cada variable?",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#modelo-de-regresión-múltiple",
    "href": "practicos/practico-03.html#modelo-de-regresión-múltiple",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Modelo de regresión múltiple",
    "text": "Modelo de regresión múltiple\nEstima el siguiente modelo:\n\nreg &lt;- lm(science ~ math + socst + female, data = data)\nsjPlot::tab_model(reg,\n                  show.se = TRUE,\n                  digits = 3,\n                  p.style = \"stars\")",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#interpretación-de-coeficientes",
    "href": "practicos/practico-03.html#interpretación-de-coeficientes",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Interpretación de coeficientes",
    "text": "Interpretación de coeficientes\n\n¿Cuál es la relación entre math y science? Explica usando el valor del coeficiente y el intervalo de confianza.\n¿Qué nos dice el intervalo de confianza sobre la significación estadística de cada predictor?\n¿Qué interpretación se puede dar al coeficiente de female?",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  },
  {
    "objectID": "practicos/practico-03.html#reflexión-final",
    "href": "practicos/practico-03.html#reflexión-final",
    "title": "Práctico 03. Regresión múltiple e inferencia",
    "section": "Reflexión final",
    "text": "Reflexión final\n\n¿Cómo ayuda el error estándar y el intervalo de confianza a interpretar la regresión?\n¿Qué diferencias observas entre variables con coeficientes estadísticamente significativos y las que no lo son?",
    "crumbs": [
      "Practicos",
      "Práctico 3 - Inferencia"
    ]
  }
]