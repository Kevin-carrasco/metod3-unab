---
title: "Metodología I"
author: ".small[Kevin Carrasco <br><br> Departamento de Sociología - UCH / COES <br><br>]"
date: "1er Sem 2025"
output:
  xaringan::moon_reader:
    css: "../../files/css/custom_2020.css"
    includes:
      after_body: "../insert-logo.html"     
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://multinivel.netlify.com/docpres/xaringan_custom/macros.js"
    seal: false # esto omite title slide automática
---
class: front

```{r eval=FALSE, include=FALSE}
# Correr esto para que funcione el infinite moonreader, el root folder debe ser static para si dirigir solo "bajndo" en directorios hacia el bib y otros

xaringan::inf_mr('/static/docpres/02_bases/2mlmbases.Rmd')

o en RStudio:
  - abrir desde carpeta root del proyecto
  - Addins-> infinite moon reader
```


```{r setup, include=FALSE, cache = FALSE}
require("knitr")
options(htmltools.dir.version = FALSE)
pacman::p_load(RefManageR)
# bib <- ReadBib("../../bib/electivomultinivel.bib", check = FALSE)
opts_chunk$set(warning=FALSE,
             message=FALSE,
             echo=FALSE,
             cache = FALSE, fig.width=7, fig.height=5.2)
pacman::p_load(flipbookr, tidyverse)
```


```{r xaringanExtra, include=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view", "animate_css"))
xaringanExtra::use_scribble()
```

<!---
Para correr en ATOM
- open terminal, abrir R (simplemente, R y enter)
- rmarkdown::render('static/docpres/07_interacciones/7interacciones.Rmd', 'xaringan::moon_reader')

About macros.js: permite escalar las imágenes como [scale 50%](path to image), hay si que grabar ese archivo js en el directorio.
--->


.pull-left[
# Metodología I
## **.yellow[Kevin Carrasco]**
## Magister Ciencias Sociales FACSO - UChile
## 1er Sem 2025 
## [.green[metod1-mcs.netlify.com]](https://metod1-mcs.netlify.com)
] 
    

.pull-right[
.right[
<br>
## .yellow[Sesión 10. Análisis factorial y regresión lineal en R]
![:scale 70%](../../files/img/eval-hires.png)

]

]
---

layout: true
class: animated, fadeIn

---
class: inverse, right

# **.red[Contenidos]**

<br>
<br>

### 1. .yellow[Análisis factorial]
### 2. Análisis de regresión lineal

---

class: middle

.pull-left-narrow[
#  Variables latentes (1)
]

.pull-right-wide[

.content-box-red[
-   La mayor parte de las variables en el mundo social no son
    directamente observables. Esto las hace constructos hipotéticos **latentes**
    
-   La medición de variables latentes se realiza a partir de indicadores observables, tales como los .red[ítems de una batería/ cuestionario]
]
]
---
class: middle

.pull-left-narrow[
#  Variables latentes (2)
]
.pull-right-wide[
.content-box-yellow[
-   Lo latente puede ser entendido como la .red[varianza compartida] por
    diferentes indicadores observados

-   La medición de variables latentes se encuentra asociada al .red[modelo de factor común] (Thurstone) y al análisis factorial
]
]
---
# Factor común

.pull-left[
-   Cada indicador en un set de medidas observadas es una .red[función lineal] de uno o más factores comunes y un factor único

-   Como referencia podemos usar la .red[teoría clásica de test] (CTT), que
    divide el puntaje de los indicadores entre puntaje verdadero y error
    ]

--

.pull-right[
<br>
$$X=T+E$$

$$\sigma^{2}_{x}=\sigma^{2}_{t} + \sigma^{2}_{e}$$

Donde
- X= puntaje observado,
- T= puntaje verdadero, y
- E= error

]
---
# Modelo de factor común

.pull-left[
-   La existencia de un solo ítem por constructo no permite aislar puntaje verdadero del error

-   Si existen más ítems, el **análisis factorial** permite
    distinguir entre **varianza común** (compartida con otros indicadores) y **varianza única** (o error)
]

.pull-right[
.center[
  ![](../../files/img/slides/figure1efa.jpg)
]
]
---
class: middle

.pull-left-narrow[
# Análisis factorial

Es un método que permite:
]

.pull-right-wide[
.content-box-gray[
- identificar la varianza común a una serie de indicadores

- establecer la contribución de cada indicador a la varianza común

- estimar posteriormente un índice (puntaje factorial) para cada factor, con mayor precisión que un promedio bruto
]]
---
# Análisis factorial

-   Un factor es una variable no observada o **latente** que da cuenta de las correlaciones entre indicadores 
    
- los indicadores están correlacionados porque comparten una causa común - concepto de **independencia condicional**

-   El o los factores darían cuenta (i.e. causarían) de la **covariación** entre una serie de medidas observadas (indicadores)

---
class: middle

.pull-left-narrow[
.content-box-red[
<br>
# Objetivos del análisis factorial
<br>
<br>
<br>
<br>
<br><br>
]]

.pull-right-wide[
<br>
-   .red[Teórico]: relacionar datos con dimensiones latentes basadas en conceptos (validez de constructo)

-   .blue[Pragmático]: hacer sentido de un conjunto de datos, reducción de
    dimensiones y obtención de puntajes

-   .green[Metodológico]: aislar el error (varianza única) de la varianza común
]

---
# Alternativas en análisis factorial

-   .red[exploratorio (EFA)]: Permite explorar las dimensiones que subyacen a una escala

-   .red[confirmatorio (CFA)]: Permite confirmar las dimensiones que subyacen a una escala, aislando el error de medición en la estimación

---
# Análisis factorial exploratorio (EFA)

-   Forma de análisis factorial donde se estiman la o las variables
    latentes a un conjunto de indicadores, **sin una especificación previa** de la estructura factorial.

--

-   Preguntas a responder:

    -   ¿Cuántos factores subyacen a un conjunto de indicadores?

    -   ¿Cómo se relacionan los indicadores con los factores?

    -   ¿Cómo es la calidad del modelo estimado?



---
.content-box-green[
# Características EFA
]

.pull-left-narrow[

.center[
<br>
  ![](../../files/img/slides/figure1efa.jpg)
]]
.pull-right-wide[
-   Basado en la matriz de correlaciones

- Modelo estandarizado (varianza factores=1)

-   Diferentes métodos de extracción de factores

-   Determinación del número y "calidad" de las dimensiones (continuas) subyacentes a una escala

]


---

.pull-left-narrow[
.content-box-purple[
<br>
# Conceptos y parámetros
<br>
<br>
<br>
<br>
<br>
]
]

.pull-right-wide[
-   **Factores**: variables latentes que están a la base de las
    correlaciones entre los indicadores

-   **Cargas factoriales**: medida estandarizada de asociación (correlación) entre el indicador y la variable latente

-   **Comunalidad**: proporción del indicador que se asocia a factor(es) comun(es)
]
---
class: middle

.pull-left-narrow[
.content-box-yellow[
<br>
# Conceptos y parámetros (2)
<br>
<br>
<br>
]
]

.pull-right-wide[
-   **Varianza única** (uniqueness): 1-comunalidad

-   **Eigenvalues**: medida de proporción de la varianza total
    correspondiente a cada uno de los factor (SS loadings)

-   **Proporción de varianza** explicada por el factor = eigenvalue /
    número de indicadores
    ]

---
class: middle

.pull-left-narrow[
.content-box-blue[
<br>
# Pasos en el análisis
<br>
<br>
<br>
]]

.pull-right-wide[
-   Estimación de matriz de correlaciones

-   Extraccion de factores

-   Decisión sobre número de factores

-   Rotación

-   Interpretación y reporte

-   Obtención de puntajes factoriales
]

---
# Supuestos a evaluar

-   Nivel de medición de variables, normalidad (eventualmente test de normalidad multivariado, ej: Shapiro Wilk multivariado)

-   Test de adecuación muestal (KMO)
.medium[
      - varía entre 0 y 1, contrasta si las correlaciones parciales entre las variables son pequeñas.

- valores pequeños (menores a 0.5) indican que los datos no serían adecuados para EFA, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables
]

---
# Supuestos a evaluar (2)

-   Nivel de correlaciones de la matriz: test de esfericidad de Bartlett

    -   se utiliza para evaluar la hipótesis que la matriz de
        correlaciones es una matriz identidad (diagonal 1 y bajo la
        diagonal 0)

    -   se busca significación (p $<$ 0.05)ya que se espera que las
        variables estén correlacionadas


---
# Metodos de extracción

-   **Factores principales**

-   **Factores principales iterados**: estima comunalidades iterativamente,
    reemplazandolas en la matriz de correlaciones a partir de las
    comunalidades estimadas desde los factor loadings

-   **Maximum likelihood**: maximiza la posibilidad de que los parametros reproduzcan los datos observados
---
# Instrumentos y criterios de selección del número de factores

-   Criterio de Kaiser: eigenvalues mayores a 1

-   Scree plot (gráfico de sedimentación)

-   **Análisis paralelo**: comparación de eigenvalues de la muestra con eigenvalues de datos aleatorios. Nº apropiado de factores: numero de eigenvalues de los datos reales que son mayores que sus correspondientes eigenvalues de datos aleatorios

---
# Screeplot y análisis paralelo

.center[
  ![:scale 60%](../../files/img/slides/parallel.PNG)
]

---

.pull-left-narrow[
# Tipos de rotación

-   **Ortogonal**: asume que los factores no se encuentran correlacionados

-   **Oblicua**: permite correlación entre factores
]

.pull-right-wide[
.center[
  ![:scale 80%](../../files/img/slides/rotate.PNG)
]
]

---
.pull-left-narrow[
## Ejemplo de análisis factorial exploratorio
]
.pull-right-wide[
.center[
  ![:scale 90%](../../files/img/fa_exploratorio.png)
  ]
  ]

---
class: roja
# Resumen

- dimensiones subyacentes = factores

- análisis factorial
  - relación entre indicadores y dimensiones
  - estimación de número de dimensiones probables subyacentes a batería
  - rotación
  - obtención de puntajes factoriales (índices ponderados)

---

class: inverse,right

# **.red[Contenidos]**

<br>
<br>

### 1. Análisis factorial
### 2. .yellow[Análisis de regresión lineal]

---

# Objetivos centrales del modelo de regresión:


1. **Conocer**: la variación de la variable dependiente de acuerdo a la variación de otra(s) variable(s) independiente(s)

2. **Predecir**: estimar el valor de una variable (dependiente) de acuerdo al valor de otra(s)

3. **Inferir**: Establecer en que medida esta asociación es estadísticamente significativa

---

# Objetivos centrales del modelo de regresión: Ejemplo

1. *Conocer*: Ej: En qué medida el puntaje PSU influye en el éxito académico en la universidad?

--

2. *Predecir*: Ej: Si una persona obtiene 600 puntos en la PSU, que promedio de notas en la universidad es probable que obtenga? (Atención: predicción no implica explicación)

--

3. *Inferir*: ¿Se puede generalizar a la población? ¿Con qué nivel de confianza?


---
class: inverse, right

## Para obtener la “mejor recta” se utiliza la estimación de mínimos cuadrados (EMC, o **OLS** – Ordinary Least Squares)

--

## OLS minimiza la suma de los **residuos** = distancias entre las observaciones y la recta en el eje vertical

---
# Componentes de la ecuación de la recta de regresión

$$\widehat{Y}=b_{0} +b_{1}X$$

Donde

- $\widehat{Y}$ es el valor estimado de $Y$

- $b_{0}$ es el intercepto de la recta (el valor de Y cuando X es 0)

- $b_{1}$ es el coeficiente de regresión, que nos dice cuánto aumenta Y por cada punto que aumenta X

---
# Estimación del modelo de regresión simple en `R`

La función para estimar regresión en `R` es `lm` (linear model):
.small[
  ```
  objeto=lm(dependiente ~ independiente, data=datos)
  ```]

Donde

- *objeto*: el nombre (cualquiera) que le damos al objeto donde se guardan los resultados de la estimación
- *dependiente / independiente*: los nombres de las variables en los datos
- *datos* = el nombre del objeto de nuestros datos en R

---
# Regresión lineal múltiple

- el **modelo de regresión** busca representar matemáticamente la relación entre una variable dependiente (Y) y una o más independientes (X)


.pull-right[
![](../../files/img/regmod3.png)
]

---
# Regresión lineal múltiple

.pull-left[

- el **modelo de regresión** busca representar matemáticamente la relación entre una variable dependiente (Y) y una o más independientes (X)

- esta relación se expresa en un parámetro $\beta$  o "beta de regresión"
]

.pull-right[
![](../../files/img/regmod4.png)
]

---
class: inverse, middle, center
# INTERPRETACIÓN

# por cada unidad que aumenta .red[X], .yellow[Y] aumenta en promedio en .orange[*Beta*] unidades.

---

# Control estadístico

- En datos observacionales de encuestas en general no hay  control por diseño, por lo que se recurre al **control estadístico**

--

- En el **modelo de regresión** se logra incluyendo predictores que teóricamente podrían dar cuenta o afectar la relación entre X e Y.

--

- La inclusión de **otros predictores** despeja o "controla" la asociación de $X_1$ e $Y$, aislando el efecto conjunto de $X_1$ y $X_2$ (... y $X_n$)

---
.pull-left-wide[
## Control estadístico
- ¿Qué efecto posee el nivel educacional en ingreso, _controlando por_ inteligencia?
]
.pull-right-narrow[
![](../../files/img/ingresoeducexp.png)
]

**Conceptualmente:**
.small[
- aislar el efecto de educación en ingreso, manteniendo la inteligencia _constante_.

- estimar el efecto de educación en ingreso independiente del efecto de la inteligencia

- estimación del efecto de educación en ingreso _ceteris paribus_ (manteniendo el efecto del resto de los predictores constante)
]

---
## Estimación de parámetros y control estadístico

- Los coeficientes de regresión $\beta$ no alteran su valor en los modelos en ausencia de correlación entre predictores $X$

--

- Si hay correlación entre predictores, el valor de los coeficientes de regresión será distinto en modelos simples y en modelos múltiples -> **control estadístico**

--

- Por ello, en regresión múltiple se habla de coeficientes de regresión **parciales**

--

- Por cada unidad que aumenta .red[X], .yellow[Y] aumenta en promedio en .orange[*Beta*] unidades, manteniendo el resto de las variables constantes.


---
# ¿Qué tan bueno es nuestro modelo?

- El cálculo del $\beta$ busca minimizar los residuos (de ahí "mínimos cuadrados ordinarios")

- Una vez minimizados los residuos, se puede evaluar el ajuste
  - qué tan bien representa nuestro modelo la realidad
  
  - cuánto error (de predicción) estamos cometiendo con nuestro modelo


---
# Varianza explicada de Y: $R^2$

- ¿Cuánto de Y puedo predecir con X (regresión) y cuánto me estoy equivocando (residuos)?

--

- el $R^2$
  - es la proporción de la varianza de Y que se asocia a X
  - varía entre 0 y 1, y se puede expresar en porcentaje

--

- Entonces, podemos descomponer la varianza de Y en 2: aquella asociada a X (regresión) y la que no se asocia a X (residuos) 

---
class: inverse

## RESUMEN

- .red[Regresión]: relación entre una variable dependiente .yellow[(Y)] y una o más independientes .red[(X)]. Por cada unidad que aumenta .red[X], .yellow[Y] aumenta en promedio en .orange[*Beta*] unidades.

- .red[Ajuste] del modelo de regresión (R2): porcentaje de la varianza de la variable dependiente (Y) que se asocia a la independiente (X) (¿qué tan bueno es nuestro modelo?) 


---
class: inverse middle

## .red[Práctica análisis factorial]
[.yellow[metod1-mcs.netlify.app/resource/04-resource.html]](https://metod1-mcs.netlify.app/resource/04-resource.html)

---
class: front

.pull-left[
# Metodología I
## **.yellow[Kevin Carrasco]**
## Magister Ciencias Sociales FACSO - UChile
## 1er Sem 2023 
## [.green[metod1-mcs.netlify.com]](https://metod1-mcs.netlify.com)
] 
    

.pull-right[
.right[
<br>
## .yellow[Sesión 10: Análisis factorial y regresión lineal en R]
![:scale 70%](../../files/img/eval-hires.png)



]

]
